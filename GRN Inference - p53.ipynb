{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p53 network - REGGaE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## TensorFlow SETUP\n",
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "from tensorflow import math as tfm\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from reggae.data_loaders import load_barenco_puma, DataHolder, barenco_params\n",
    "from reggae.mcmc import create_chains, MetropolisHastings, Parameter\n",
    "from reggae.utilities import discretise, logit, LogisticNormal, inverse_positivity\n",
    "from reggae.plot import plotters\n",
    "from reggae.models import TranscriptionLikelihood, Options, TranscriptionMixedSampler\n",
    "from reggae.models.results import GenericResults\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import HTML\n",
    "plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\Users\\\\Jacob\\\\Documents\\\\ffmpeg-static\\\\bin\\\\ffmpeg.exe'\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "f64 = np.float64\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.4f}\".format(x)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_observed, f_observed, σ2_m_pre, σ2_f_pre, t = load_barenco_puma()\n",
    "\n",
    "# m_observed, f_observed, t = load_3day_dros()\n",
    "\n",
    "replicate = 0\n",
    "\n",
    "m_df, m_observed = m_observed \n",
    "f_df, f_observed = f_observed\n",
    "# Shape of m_observed = (replicates, genes, times)\n",
    "m_observed = m_observed\n",
    "f_observed = f_observed\n",
    "σ2_m_pre = f64(σ2_m_pre)\n",
    "σ2_f_pre = f64(σ2_f_pre)\n",
    "\n",
    "num_genes = m_observed.shape[1]\n",
    "τ, common_indices = discretise(t, num_disc=13)\n",
    "N_p = τ.shape[0]\n",
    "N_m = m_observed.shape[1]\n",
    "\n",
    "data = (m_observed, f_observed)\n",
    "noise_data = (σ2_m_pre, σ2_f_pre)\n",
    "time = (t, τ, tf.constant(common_indices))\n",
    "\n",
    "data = DataHolder(data, noise_data, time)\n",
    "N_p = τ.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = Options(preprocessing_variance=True, \n",
    "              tf_mrna_present=False, \n",
    "              delays=False,\n",
    "              weights=False,\n",
    "              translation=False,\n",
    "              initial_conditions=False,\n",
    "              initial_step_sizes={'logistic': 0.00001, 'latents': 10},\n",
    "              kernel='rbf')\n",
    "name = 'p53' if opt.tf_mrna_present else 'p53-notf'\n",
    "model = TranscriptionMixedSampler(data, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise from saved model:\n",
    "model = TranscriptionMixedSampler.load(name, [data, opt])\n",
    "is_accepted = model.is_accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "samples, is_accepted = model.sample(T=500, burn_in=0)\n",
    "end = timer()\n",
    "print(f'Time taken: {(end - start):.04f}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(name)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first clear C:\\Users\\Jacob\\AppData\\Local\\Temp\\.tensorboard-info\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/reggae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samples, is_accepted = model.sample(T=1, burn_in=0, profile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr><th>Processor</th><th># Iterations</th><th>Time</th><th>Note</th></tr>\n",
    "    <tr><td>CPU</td><td>20</td><td>54.7s</td><td></td></tr>\n",
    "    <tr><td>CPU</td><td>20</td><td>38.4s</td><td>Merged weight and kinetics</td></tr>\n",
    "    <tr><td>CPU</td><td>200</td><td>436.2s</td><td></td></tr>\n",
    "    <tr><td>CPU</td><td>200</td><td>396.1s</td><td>No prob update</td></tr>\n",
    "    <tr><td>CPU</td><td>800</td><td>901.9s</td><td>No prob update, merged w,k</td></tr>\n",
    "    <tr><td>CPU</td><td>1000</td><td>900s</td><td>no intial cond, no protein</td></tr>\n",
    "    <tr><td>GPU</td><td>2</td><td>40.8s</td><td></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcs = list()\n",
    "for i, param in enumerate(model.state_indices):\n",
    "    pcs.append(tf.reduce_mean(tf.cast(is_accepted[i], dtype=tf.float32)).numpy())\n",
    "\n",
    "display(pd.DataFrame([[f'{100*pc:.02f}%' for pc in pcs]], columns=list(model.state_indices)))\n",
    "\n",
    "σ2_f = None\n",
    "results = model.results()\n",
    "k_latest = np.mean(results.k[-100:], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BARENCO\n",
    "barenco = barenco_params()\n",
    "if opt.tf_mrna_present:\n",
    "    k_true = barenco / np.mean(barenco, axis=0) * np.mean(k_latest[:,1:], axis=0)\n",
    "    k_true = np.c_[np.zeros(num_genes), k_true]\n",
    "else: \n",
    "    k_true = barenco / np.mean(barenco, axis=0) * np.mean(k_latest, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPARISON TO MH\n",
    "k_true = np.array([[0.28157, 2.48264, 9.05267],\n",
    "          [0.07394, 2.64863, 7.10769],\n",
    "          [0.54263, 8.78634, 19.73215],\n",
    "          [0.26399, 8.04371, 7.49752],\n",
    "          [0.23321, 3.66627, 11.41177]])\n",
    "\n",
    "k_true = k_true / np.mean(k_true, axis=0) * np.mean(k_latest, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_opt = plotters.PlotOptions(\n",
    "    num_plot_genes=10, num_plot_tfs=10,\n",
    "    gene_names=m_df.index, tf_names=f_df.index, \n",
    "    for_report=True, protein_present=False, tf_present=False,\n",
    "    kernel_names=model.kernel_selector.names(), \n",
    "    true_label='Barenco et al.', model_label='REGGaE', num_kinetic_avg=100\n",
    ")\n",
    "plotter = plotters.Plotter(data, plot_opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_preds = model.sample_latents(results, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotter.summary(results, m_preds, replicate=0, true_k=k_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.k.shape)\n",
    "plotter.plot_convergence(results.k[-2000:, 0, 1], lims=(0, 3.5), fig_height=4.5, fig_width=6.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbar = results.kbar[-1]\n",
    "print(kbar[3, 0])\n",
    "kbar[3, 0] = 0.57\n",
    "m_pred = model.likelihood.predict_m(kbar, None, results.wbar[-1], results.fbar[-1],\n",
    "                           results.w_0bar[-1], None)\n",
    "plt.plot(τ, m_pred[0, 3])\n",
    "plt.scatter(t, m_observed[0, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hpds[:, 2].swapaxes(0,1).shape)\n",
    "\n",
    "plotter.plot_kinetics(results.k, results.k_f, true_k=k_true, true_hpds=hpds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotter.convergence_summary(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_tfs(results.f, replicate=0, sample_gap=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(plotter.anim_latent(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "k = results.k\n",
    "k_latest = np.mean(results.k[-50:], axis=0)\n",
    "print(k_latest)\n",
    "k_latest = preprocessing.normalize(k_latest)\n",
    "print(k_latest)\n",
    "num_genes = results.k.shape[1]\n",
    "true_data = None\n",
    "plot_labels = ['Initial Conditions', 'Basal rates', 'Decay rates', 'Sensitivities']\n",
    "\n",
    "hpds = list()\n",
    "for j in range(num_genes):\n",
    "    hpds.append(arviz.hpd(k[-50:, j,:], credible_interval=0.95))\n",
    "hpds = np.array(hpds)\n",
    "hpds = abs(hpds - np.expand_dims(k_latest, 2))\n",
    "\n",
    "width = 18 if num_genes > 10 else 10\n",
    "plt.figure(figsize=(width, 16))\n",
    "comparison_label = 'Barenco et al.'\n",
    " \n",
    "true_data = barenco / np.mean(barenco, axis=0) * np.mean(k_latest, axis=0)\n",
    "plot_labels = plot_labels[1:]\n",
    "# true_data = preprocessing.normalize(true_data)\n",
    "plotnum = 421\n",
    "for k in range(k_latest.shape[1]):\n",
    "    plt.subplot(plotnum)\n",
    "    plotnum+=1\n",
    "    plt.bar(np.arange(num_genes)-0.2, k_latest[:, k], width=0.4, tick_label=m_df.index, label='Model')\n",
    "    if true_data is not None:\n",
    "        plt.bar(np.arange(num_genes)+0.2, true_data[:, k], width=0.4, color='blue', align='center', label=comparison_label)\n",
    "    plt.title(plot_labels[k])\n",
    "    plt.errorbar(np.arange(num_genes)-0.2, k_latest[:, k], hpds[:, k].swapaxes(0,1), fmt='none', capsize=5, color='black')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=70)\n",
    "plt.tight_layout(h_pad=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_samples = model.sample_proteins(results, 20)\n",
    "print(p_samples.shape)\n",
    "plotter.plot_samples(p_samples[:,0], [''], 4, color='orangered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run just the Latent sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from reggae.mcmc.kernels import MixedKernel, LatentKernel\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "all_states = [param.value for param in model.active_params]\n",
    "\n",
    "def trace_fn(a, previous_kernel_results):\n",
    "    return previous_kernel_results.is_accepted\n",
    "\n",
    "iters = 50000\n",
    "@tf.function\n",
    "def run_chain():\n",
    "    # Run the chain (with burn-in).\n",
    "    samples, is_accepted = tfp.mcmc.sample_chain(\n",
    "          num_results=iters,\n",
    "          num_burnin_steps=0,\n",
    "          current_state=all_states,\n",
    "          kernel=mixed_kern,\n",
    "          trace_fn=trace_fn)\n",
    "\n",
    "    return samples, is_accepted\n",
    "\n",
    "latent_kern = LatentKernel(model.data, model.options, model.likelihood, model.kernel_selector, \n",
    "                           model.state_indices, 2*tf.ones(N_p, dtype='float64'))\n",
    "kernels = [model.active_params[0].kernel, latent_kern, model.active_params[2].kernel]\n",
    "mixed_kern = MixedKernel(kernels, [True, False, False], iters, skip=[True, False, True])\n",
    "\n",
    "chain_result = run_chain();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain_result[0][1][0].shape)\n",
    "f = chain_result[0][1][0]\n",
    "print(f.shape)\n",
    "print(data.f_obs[0][0])\n",
    "plt.scatter(τ[common_indices], data.f_obs[0,0])\n",
    "plt.plot(τ, inverse_positivity(f[-1,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "num_genes = kbar.shape[1]\n",
    "k_latest = np.mean(logit(kbar[-10:]), axis=0)\n",
    "print(k_latest)\n",
    "B = k_latest[:,1]\n",
    "D = k_latest[:,2]\n",
    "S = k_latest[:,3]\n",
    "\n",
    "plt.bar(np.arange(num_genes)-0.2, B, width=0.2, tick_label=m_df.index, label='Basal rate')\n",
    "plt.bar(np.arange(num_genes), D, width=0.2, tick_label=m_df.index, label='Sensitivity')\n",
    "plt.bar(np.arange(num_genes)+0.2, S, width=0.2, tick_label=m_df.index, label='Decay rate')\n",
    "plt.yscale('log')\n",
    "plt.title('Mechanistic Parameters')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keys = job[0].acceptance_rates.keys()\n",
    "\n",
    "variables = {key : np.empty((0, T, *job[0].samples[key].get().shape[1:])) for key in keys}\n",
    "\n",
    "for res in job:\n",
    "    for key in keys:\n",
    "        variables[key] = np.append(variables[key], np.expand_dims(res.samples[key].get(), 0), axis=0)\n",
    "\n",
    "plt.plot(variables['L'][:,-100:].T)\n",
    "\n",
    "mixes = {key: arviz.convert_to_inference_data(variables[key]) for key in keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rhat\n",
    "Rhat is the ratio of posterior variance and within-chain variance. If the ratio exceeds 1.1 then we consider the chains have not mixed well. As the between-chain variance tends to the within-chain then R tends to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Rhat = arviz.rhat(mixes['fbar'])\n",
    "\n",
    "Rhats = np.array([np.mean(arviz.rhat(mixes[key]).x.values) for key in keys])\n",
    "\n",
    "rhat_df = pd.DataFrame([[*Rhats], [*(Rhats < 1.1)]], columns=keys)\n",
    "\n",
    "display(rhat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank plots\n",
    "\n",
    "Rank plots are histograms of the ranked posterior draws (ranked over all\n",
    "    chains) plotted separately for each chain.\n",
    "    If all of the chains are targeting the same posterior, we expect the ranks in each chain to be\n",
    "    uniform, whereas if one chain has a different location or scale parameter, this will be\n",
    "    reflected in the deviation from uniformity. If rank plots of all chains look similar, this\n",
    "    indicates good mixing of the chains.\n",
    "\n",
    "Rank-normalization, folding, and localization: An improved R-hat\n",
    "    for assessing convergence of MCMC. arXiv preprint https://arxiv.org/abs/1903.08008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arviz.plot_rank(L_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effective sample sizes\n",
    "\n",
    "Plot quantile, local or evolution of effective sample sizes (ESS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arviz.plot_ess(L_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monte-Carlo Standard Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arviz.plot_mcse(L_mix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Plot\n",
    "Plot parallel coordinates plot showing posterior points with and without divergences.\n",
    "\n",
    "Described by https://arxiv.org/abs/1709.01449, suggested by Ari Hartikainen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arviz.plot_parallel(azl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step size is standard dev, too small means it takes long time to reach high density areas. too long means we reject many of samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit374b75da0e1b40de8b7922d3f142c01d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
