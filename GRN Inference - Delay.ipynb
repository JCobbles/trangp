{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reggae.models import TranscriptionLikelihood, Options\n",
    "from reggae.data_loaders import load_barenco_puma, load_3day_dros, DataHolder, scaled_barenco_data\n",
    "from reggae.utilities import get_rbf_dist, discretise, logit, logistic, LogisticNormal\n",
    "from reggae.mcmc import create_chains, MetropolisHastings, Parameter\n",
    "from reggae.plot import plotters\n",
    "from reggae.models.kernels import MixedKernel, FKernel, KbarKernel\n",
    "from reggae.models.results import GenericResults\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import math as tfm\n",
    "from tensorflow_probability import distributions as tfd\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "f64 = np.float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_genes = 5\n",
    "t = np.arange(10)\n",
    "τ, common_indices = discretise(t)\n",
    "time = (t, τ, tf.constant(common_indices))\n",
    "opt = Options(preprocessing_variance=False, tf_mrna_present=True, delays=True)\n",
    "\n",
    "N_p = τ.shape[0]\n",
    "N_m = t.shape[0]\n",
    "\n",
    "num_tfs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcription factor\n",
    "\n",
    "A = np.array([0.01, 0.3, 0.47, 0.51, 0.4, 0.37, 0.47, 0.32, 0.16, 0.025])\n",
    "B = np.array([0.01, 0.1, 0.22, 0.44, 0.53, 0.41, 0.23, 0.13, 0.05, 0.013])\n",
    "C = np.array([0.01, 0.02, 0.03, 0.05, 0.08, 0.16, 0.4, 0.36, 0.23, 0.02])\n",
    "interp = interp1d(np.arange(A.shape[0]), A, kind='cubic')\n",
    "A = interp(np.linspace(0,9, τ.shape[0]))\n",
    "interp = interp1d(np.arange(B.shape[0]), B, kind='cubic')\n",
    "B = interp(np.linspace(0,9, τ.shape[0]))\n",
    "interp = interp1d(np.arange(C.shape[0]), C, kind='quadratic')\n",
    "C = interp(np.linspace(0,9, τ.shape[0]))\n",
    "\n",
    "δbar = logistic(f64(np.array([1.5, 1.5, 1.5])))\n",
    "\n",
    "fbar = np.array([A, B, C])\n",
    "fbar = 5*preprocessing.normalize(fbar)\n",
    "print(fbar.shape)\n",
    "tf_labels = ['A', 'B', 'C']\n",
    "plt.title('TFs')\n",
    "\n",
    "#Take observations\n",
    "f_observed = tf.stack([fbar[i][common_indices] for i in range(num_tfs)])\n",
    "\n",
    "for i in range(num_tfs):\n",
    "    plt.plot(np.arange(τ.shape[0]), fbar[i], label=f'TF {i}')\n",
    "    plt.scatter(np.arange(N_p)[common_indices], f_observed[i], marker='x')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "fbar = tfm.log((tfm.exp(fbar)-1))\n",
    "\n",
    "f_i = tfm.log(1+tfm.exp(fbar))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w = 1*tf.ones((num_genes, num_tfs), dtype='float64') # TODO\n",
    "w_0 = tf.zeros(num_genes, dtype='float64') # TODO\n",
    "true_kbar = logistic(np.array([[0.2061, 0.2475, 0.8222, 4.0416],\n",
    "                       [0.4091, 0.7305, 0.9486, 2.2348],\n",
    "                       [0.1304, 0.3921, 2.3116, 7.1835],\n",
    "                       [0.3789, 0.2861, 1.2456, 0.9928],\n",
    "                       [0.2906, 0.6604, 0.8742, 4.1688]]))\n",
    "true_kbar = logistic(np.array([[0.2148, 0.2192, 0.5675, 2.7892],\n",
    "                         [0.3172, 0.8753, 0.9294, 1.0161],\n",
    "                         [0.1133, 0.2964, 0.7675, 2.6464],\n",
    "                         [0.4087, 0.4333, 1.2619, 0.9654],\n",
    "                         [0.2490, 0.1860, 0.7592, 3.3507]]))\n",
    "print(true_kbar)\n",
    "\n",
    "temp_data = DataHolder((np.ones((num_genes, N_m)), np.ones((num_tfs, N_m))), None, time)\n",
    "temp_lik = TranscriptionLikelihood(temp_data, opt)\n",
    "Δbar = logistic(tf.constant([0, 0, 0], dtype='float64'))\n",
    "m_pred1 = temp_lik.predict_m(true_kbar, δbar, w, fbar, w_0, Δbar)\n",
    "Δbar = logistic(tf.constant([1, 4, 8], dtype='float64'))\n",
    "m_pred = temp_lik.predict_m(true_kbar, δbar, w, fbar, w_0, Δbar)\n",
    "\n",
    "m_observed = tf.stack([m_pred.numpy()[i][common_indices] for i in range(num_genes)])\n",
    "m_observed_nodelay = tf.stack([m_pred1.numpy()[i][common_indices] for i in range(num_genes)])\n",
    "\n",
    "def plot_genes(tup1, tup2):\n",
    "    #Take observations\n",
    "\n",
    "    for j in range(num_genes):\n",
    "        plt.subplot(num_genes*100+21+j)\n",
    "        plt.title(f'Gene {j}')\n",
    "        plt.scatter(np.arange(N_p)[common_indices], tup1[1][j], marker='x', label=tup1[2])\n",
    "        plt.plot(tup1[0][j], color='grey')\n",
    "        plt.scatter(np.arange(N_p)[common_indices], tup2[1][j], marker='x', label=tup2[2])\n",
    "        plt.plot(tup2[0][j], color='grey')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    \n",
    "plt.figure(figsize=(10, 13))\n",
    "\n",
    "plot_genes((m_pred1, m_observed_nodelay, 'no delay'), (m_pred, m_observed, 'delay'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (m_observed, f_observed)\n",
    "\n",
    "data = DataHolder(data, None, time)\n",
    "\n",
    "opt = Options(preprocessing_variance=False, tf_mrna_present=True, delays=True)\n",
    "lik = TranscriptionLikelihood(data, opt)\n",
    "\n",
    "plt.title('TF Proteins')\n",
    "Δbar = logistic(tf.constant([0, 0, 0], dtype='float64'))\n",
    "p = lik.calculate_protein(fbar, δbar, Δbar)\n",
    "Δbar = logistic(tf.constant([1, 4, 8], dtype='float64'))\n",
    "p_delay = lik.calculate_protein(fbar, δbar, Δbar)\n",
    "\n",
    "for i in range(num_tfs):\n",
    "    plt.plot(p[i], label=f'Protein {i}')\n",
    "    plt.plot(p_delay[i], label=f'Protein {i}')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaKernel(tfp.mcmc.TransitionKernel):\n",
    "    def __init__(self, likelihood, lower, upper, state_indices):\n",
    "        self.num_genes = num_genes\n",
    "        self.likelihood = likelihood\n",
    "        self.state_indices = state_indices\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        \n",
    "    def one_step(self, current_state, previous_kernel_results, all_states):\n",
    "        num_tfs = current_state.shape[0]\n",
    "        new_state = logit(current_state)\n",
    "        Δrange = np.arange(self.lower, self.upper+1, dtype='float64')\n",
    "        Δrange_tf = tf.range(self.lower, self.upper+1, dtype='float64')\n",
    "        for i in range(num_tfs):\n",
    "            # Generate normalised cumulative distribution\n",
    "            cumsum = list()\n",
    "            mask = np.zeros((num_tfs, ), dtype='float64')\n",
    "            mask[i] = 1\n",
    "            \n",
    "            for j, Δ in enumerate(Δrange):\n",
    "                test_state = (1-mask) * new_state + mask * logistic(Δ)\n",
    "\n",
    "                if j == 0:\n",
    "                    cumsum.append(tf.reduce_sum(self.likelihood.genes(\n",
    "                        all_states=all_states, \n",
    "                        state_indices=self.state_indices,\n",
    "                        Δbar=test_state,\n",
    "                    )))# + tf.reduce_sum(self.params.Δbar.prior.log_prob(logit(Δbar)))\n",
    "                else:\n",
    "                    cumsum.append(cumsum[j-1] + tf.reduce_sum(self.likelihood.genes(\n",
    "                        all_states=all_states, \n",
    "                        state_indices=self.state_indices,\n",
    "                        Δbar=test_state,\n",
    "                    )))# + tf.reduce_sum(self.params.Δbar.prior.log_prob(logit(Δbar)))\n",
    "            cumsum = tf.stack(cumsum)\n",
    "            cumsum /= cumsum[-1]\n",
    "#             tf.print('noramlised', cumsum)\n",
    "            u = np.random.uniform()\n",
    "            index = tf.where(cumsum == tf.reduce_min(cumsum[(cumsum - u) > 0]))\n",
    "#             tf.print(index[0][0])\n",
    "#             tf.print('chosen', Δrange_tf[index[0][0]])\n",
    "            chosen = Δrange_tf[index[0][0]]\n",
    "            new_state = (1-mask) * new_state + mask * logistic(chosen)\n",
    "            \n",
    "#         tf.print('final chosen state', new_state)\n",
    "\n",
    "        return new_state, GenericResults(list(), True)\n",
    "\n",
    "    def bootstrap_results(self, init_state, all_states):\n",
    "        probs = list()\n",
    "\n",
    "        return GenericResults(list(), True)\n",
    "    \n",
    "    def is_calibrated(self):\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "TupleParams_pre = collections.namedtuple('TupleParams_pre', [\n",
    "    'fbar','δbar','kbar','σ2_m','w','w_0','L','V','Δbar', 'σ2_f'\n",
    "])\n",
    "TupleParams = collections.namedtuple('TupleParams', [\n",
    "    'fbar','δbar','kbar','σ2_m','w','w_0','L','V','Δbar'\n",
    "])\n",
    "\n",
    "class TranscriptionCustom():\n",
    "    '''\n",
    "    Data is a tuple (m, f) of shapes (num, time)\n",
    "    time is a tuple (t, τ, common_indices)\n",
    "    '''\n",
    "    def __init__(self, data: DataHolder, options: Options):\n",
    "        self.data = data\n",
    "        self.samples = None\n",
    "        min_dist = min(data.t[1:]-data.t[:-1])\n",
    "        self.N_p = data.τ.shape[0]\n",
    "        self.N_m = data.t.shape[0]      # Number of observations\n",
    "\n",
    "        self.num_tfs = data.f_obs.shape[0] # Number of TFs\n",
    "        self.num_genes = data.m_obs.shape[0]\n",
    "\n",
    "        self.likelihood = TranscriptionLikelihood(data, options)\n",
    "        self.options = options\n",
    "        # Adaptable variances\n",
    "        a = tf.constant(-0.5, dtype='float64')\n",
    "        b2 = tf.constant(2., dtype='float64')\n",
    "        self.state_indices = {\n",
    "            'δbar': 0,\n",
    "            'kbar': 1,\n",
    "            'fbar': 2, \n",
    "            'rbf_params': 3,\n",
    "            'σ2_m': 4,\n",
    "            'Δbar': 5,\n",
    "            'w': 5,\n",
    "        }\n",
    "        logistic_step_size = 0.00001\n",
    "\n",
    "        # Interaction weights\n",
    "        def w_log_prob(all_states):\n",
    "            def w_log_prob_fn(wstar, w_0star):\n",
    "                new_prob = tf.reduce_sum(self.likelihood.genes(\n",
    "                    all_states=all_states, \n",
    "                    state_indices=self.state_indices,\n",
    "                     w=wstar))\n",
    "                new_prob += tf.reduce_sum(self.params.w.prior.log_prob(wstar)) \n",
    "                new_prob += tf.reduce_sum(self.params.w_0.prior.log_prob(w_0star))\n",
    "                return tf.reduce_sum(new_prob)\n",
    "            return w_log_prob_fn\n",
    "        w = Parameter('w', tfd.Normal(f64(0), f64(2)), \n",
    "                      1*tf.ones((self.num_genes, self.num_tfs), dtype='float64'), \n",
    "                      step_size=0.04, hmc_log_prob=w_log_prob, requires_all_states=True)\n",
    "        w_0 = Parameter('w_0', tfd.Normal(f64(0), f64(2)), tf.zeros(self.num_genes, dtype='float64'))\n",
    "\n",
    "        # Latent function\n",
    "        fbar_kernel = FKernel(self.likelihood, \n",
    "                              self.fbar_prior_params, \n",
    "                              self.num_tfs, self.num_genes, \n",
    "                              self.options.tf_mrna_present, \n",
    "                              self.state_indices,\n",
    "                              0.1*tf.ones(N_p, dtype='float64'))\n",
    "        fbar = Parameter('fbar', self.fbar_prior, 0.5*tf.ones((self.num_tfs, self.N_p), dtype='float64'),\n",
    "                         kernel=fbar_kernel, requires_all_states=False)\n",
    "\n",
    "        # GP hyperparameters\n",
    "        def rbf_params_log_prob(all_states):\n",
    "            def rbf_params_log_prob(vbar, l2bar):\n",
    "                v = logit(vbar, nan_replace=self.params.V.prior.b)\n",
    "                l2 = logit(l2bar, nan_replace=self.params.L.prior.b)\n",
    "\n",
    "                new_prob = tf.reduce_sum(self.params.fbar.prior(all_states[self.state_indices['fbar']], vbar, l2bar))\n",
    "#                 tf.print(new_prob)\n",
    "                new_prob += self.params.V.prior.log_prob(v)\n",
    "                new_prob += self.params.L.prior.log_prob(l2)\n",
    "#                 tf.print('new prob', new_prob)\n",
    "#                 if new_prob < -1e3:\n",
    "#                     tf.print(all_states[self.state_indices['fbar']], v, l2)\n",
    "                return tf.reduce_sum(new_prob)\n",
    "            return rbf_params_log_prob\n",
    "\n",
    "        V = Parameter('rbf_params', LogisticNormal(f64(1e-4), f64(1+max(np.var(data.f_obs, axis=1))),allow_nan_stats=False), \n",
    "                      [0.75*tf.ones(self.num_tfs, dtype='float64'), 0.95*tf.ones(self.num_tfs, dtype='float64')], \n",
    "                      step_size=logistic_step_size, fixed=not options.tf_mrna_present, \n",
    "                      hmc_log_prob=rbf_params_log_prob, requires_all_states=True)\n",
    "        L = Parameter('L', LogisticNormal(f64(min_dist**2-0.2), f64(data.t[-1]**2), allow_nan_stats=False), None)\n",
    "\n",
    "        self.t_dist = get_rbf_dist(data.τ, self.N_p)\n",
    "\n",
    "        # Translation kinetic parameters\n",
    "        def δbar_log_prob(all_states):\n",
    "            def δbar_log_prob_fn(state):\n",
    "#                 chain_probs = list()\n",
    "#                 new_prob = None\n",
    "#                 for chain in range(state.shape[0]):\n",
    "                new_prob = tf.reduce_sum(self.likelihood.genes(\n",
    "                    all_states=all_states, \n",
    "                    state_indices=self.state_indices,\n",
    "                    δbar=state\n",
    "                ))\n",
    "                new_prob += self.params.δbar.prior.log_prob(logit(state))\n",
    "#                 chain_probs.append(new_prob)\n",
    "                    \n",
    "#                 tf.print(tf.constant(chain_probs))\n",
    "                return new_prob\n",
    "            return δbar_log_prob_fn\n",
    "        δbar = Parameter('δbar', LogisticNormal(0.1, 3), 0.7*tf.ones((self.num_tfs,), dtype='float64'), step_size=logistic_step_size, \n",
    "                         hmc_log_prob=δbar_log_prob, requires_all_states=True)\n",
    "\n",
    "        # White noise for genes\n",
    "        def σ2_m_log_prob(all_states):\n",
    "            def σ2_m_log_prob_fn(σ2_mstar):\n",
    "#                 tf.print('star:',σ2_mstar)\n",
    "                new_prob = self.likelihood.genes(\n",
    "                    all_states=all_states, \n",
    "                    state_indices=self.state_indices,\n",
    "                    σ2_m=σ2_mstar \n",
    "                ) + self.params.σ2_m.prior.log_prob(logit(σ2_mstar))\n",
    "#                 tf.print('prob', tf.reduce_sum(new_prob))\n",
    "                return tf.reduce_sum(new_prob)                \n",
    "            return σ2_m_log_prob_fn\n",
    "        σ2_m = Parameter('σ2_m', LogisticNormal(f64(1e-5), f64(max(np.var(data.f_obs, axis=1)))), 1e-4*tf.ones(self.num_genes, dtype='float64'), \n",
    "                         hmc_log_prob=σ2_m_log_prob, requires_all_states=True, step_size=logistic_step_size)\n",
    "        # Transcription kinetic parameters\n",
    "        def constrain_kbar(kbar, gene):\n",
    "            '''Constrains a given row in kbar'''\n",
    "#             if gene == 3:\n",
    "#                 kbar[2] = np.log(0.8)\n",
    "#                 kbar[3] = np.log(1.0)\n",
    "            kbar[kbar < -10] = -10\n",
    "            kbar[kbar > 3] = 3\n",
    "            return kbar\n",
    "        kbar_initial = 0.6*np.float64(np.c_[ # was -0.1\n",
    "            np.ones(self.num_genes), # a_j\n",
    "            np.ones(self.num_genes), # b_j\n",
    "            np.ones(self.num_genes), # d_j\n",
    "            np.ones(self.num_genes)  # s_j\n",
    "        ])\n",
    "        def kbar_log_prob(all_states):\n",
    "            def kbar_log_prob_fn(kstar):\n",
    "#                 tf.print(kstar)\n",
    "                k = logit(kstar)\n",
    "#                 tf.print(k)\n",
    "                new_prob = self.likelihood.genes(\n",
    "                    all_states=all_states, \n",
    "                    state_indices=self.state_indices,\n",
    "                    kbar=kstar, \n",
    "                ) + tf.reduce_sum(self.params.kbar.prior.log_prob(k))\n",
    "#                 tf.print(new_prob)\n",
    "                return tf.reduce_sum(new_prob)\n",
    "            return kbar_log_prob_fn\n",
    "        for j, k in enumerate(kbar_initial):\n",
    "            kbar_initial[j] = constrain_kbar(k, j)\n",
    "        kbar = Parameter('kbar', LogisticNormal(0.01, 8), \n",
    "                         kbar_initial,\n",
    "                         hmc_log_prob=kbar_log_prob,\n",
    "                         constraint=constrain_kbar, step_size=logistic_step_size, requires_all_states=True)\n",
    "        \n",
    "\n",
    "        delta_kernel = DeltaKernel(self.likelihood, 0, 10, self.state_indices)\n",
    "        Δbar = Parameter('Δbar', LogisticNormal(f64(0), f64(10)), 0.6*tf.ones(self.num_tfs, dtype='float64'),\n",
    "                        kernel=delta_kernel, requires_all_states=False)\n",
    "        \n",
    "        if not options.preprocessing_variance:\n",
    "            σ2_f = Parameter('σ2_f', tfd.InverseGamma(f64(0.01), f64(0.01)), 1e-4*np.ones(self.num_tfs), step_size=tf.constant(0.5, dtype='float64'))\n",
    "            self.params = TupleParams_pre(fbar, δbar, kbar, σ2_m, w, w_0, L, V, Δbar, σ2_f)\n",
    "        else:\n",
    "            self.params = TupleParams(fbar, δbar, kbar, σ2_m, w, w_0, L, V, Δbar)\n",
    "            \n",
    "    def fbar_prior_params(self, vbar, l2bar):\n",
    "        v = logit(vbar, nan_replace=self.params.V.prior.b)\n",
    "        l2 = logit(l2bar, nan_replace=self.params.L.prior.b)\n",
    "\n",
    "#         tf.print('vl2', v, l2)\n",
    "        sq_dist = tf.divide(tfm.square(self.t_dist), tf.reshape(2*l2, (-1, 1, 1)))\n",
    "        K = tf.reshape(v, (-1, 1, 1)) * tfm.exp(-sq_dist)\n",
    "        m = tf.zeros((self.N_p), dtype='float64')\n",
    "        return m, K\n",
    "\n",
    "    def fbar_prior(self, fbar, v, l2):\n",
    "        m, K = self.fbar_prior_params(v, l2)\n",
    "#         tf.print(fbar[0][:6])\n",
    "#         tf.print(v, l2)\n",
    "        jitter = tf.linalg.diag(1e-8 *tf.ones(self.N_p, dtype='float64'))\n",
    "        prob = 0\n",
    "        for i in range(self.num_tfs):\n",
    "            prob += tfd.MultivariateNormalTriL(loc=m, scale_tril=tf.linalg.cholesky(K[i]+jitter)).log_prob(fbar[i])\n",
    "#         tf.print('fbar prob:', tf.reduce_sum(prob))\n",
    "#         try:\n",
    "        return prob\n",
    "#         except:\n",
    "#             jitter = tf.linalg.diag(1e-4 *tf.ones(self.N_p, dtype='float64'))\n",
    "#             try:\n",
    "#                 return tfd.MultivariateNormalFullCovariance(m, K+jitter).log_prob(fbar)\n",
    "#             except Exception as e:\n",
    "#                 tf.print(\"Fbar prior error\", e)\n",
    "#                 raise e\n",
    "#                 return tf.constant(-np.inf, dtype='float64')\n",
    "\n",
    "\n",
    "    def sample(self, T=2000, store_every=10, burn_in=1000, report_every=100, num_chains=4):\n",
    "        print('----- Sampling Begins -----')\n",
    "        \n",
    "        params = self.params\n",
    "        progbar = tf.keras.utils.Progbar(\n",
    "            100, width=30, verbose=1, interval=0.05, stateful_metrics=None,\n",
    "            unit_name='step'\n",
    "        )\n",
    "\n",
    "        active_params = [\n",
    "            params.δbar,\n",
    "            params.kbar,\n",
    "            params.fbar,\n",
    "            params.V,\n",
    "            params.σ2_m,\n",
    "            params.Δbar,\n",
    "            #params.w,\n",
    "        ]\n",
    "        kernels = [param.kernel for param in active_params]\n",
    "#         if self.options.tf_mrna_present:\n",
    "        send_all_states = [param.requires_all_states for param in active_params]\n",
    "\n",
    "        current_state = [\n",
    "#             tf.stack([params.δbar.value for _ in range(num_chains)], axis=0),\n",
    "            params.δbar.value,\n",
    "            params.kbar.value, \n",
    "            params.fbar.value, \n",
    "            [*params.V.value],\n",
    "            params.σ2_m.value,\n",
    "            params.Δbar.value,\n",
    "            #[params.w.value, params.w_0.value]\n",
    "        ]\n",
    "        mixed_kern = MixedKernel(kernels, send_all_states)\n",
    "        \n",
    "        def trace_fn(a, previous_kernel_results):\n",
    "            return previous_kernel_results.is_accepted\n",
    "\n",
    "        # Run the chain (with burn-in).\n",
    "        @tf.function\n",
    "        def run_chain():\n",
    "            # Run the chain (with burn-in).\n",
    "            samples, is_accepted = tfp.mcmc.sample_chain(\n",
    "                  num_results=T,\n",
    "                  num_burnin_steps=burn_in,\n",
    "                  current_state=current_state,\n",
    "                  kernel=mixed_kern,\n",
    "                  trace_fn=trace_fn)\n",
    "\n",
    "            return samples, is_accepted\n",
    "\n",
    "        samples, is_accepted = run_chain()\n",
    "\n",
    "        add_to_previous = (self.samples is not None)\n",
    "        for param in active_params:\n",
    "            index = self.state_indices[param.name]\n",
    "            param_samples = samples[index]\n",
    "            if type(param_samples) is list:\n",
    "                if add_to_previous:\n",
    "                    for i in range(len(param_samples)):\n",
    "                        self.samples[index][i] = tf.concat([self.samples[index][i], samples[index][i]], axis=0)\n",
    "                param_samples = [[param_samples[i][-1] for i in range(len(param_samples))]]\n",
    "            else:\n",
    "                if add_to_previous:\n",
    "                    self.samples[index] = tf.concat([self.samples[index], samples[index]], axis=0)\n",
    "            param.value = param_samples[-1]\n",
    "\n",
    "        if not add_to_previous:\n",
    "            self.samples = samples     \n",
    "        self.is_accepted = is_accepted\n",
    "        print('----- Finished -----')\n",
    "        return samples, is_accepted\n",
    "        \n",
    "            \n",
    "    @staticmethod\n",
    "    def initialise_from_state(args, state):\n",
    "        model = TranscriptionMCMC(*args)\n",
    "        model.acceptance_rates = state.acceptance_rates\n",
    "        model.samples = state.samples\n",
    "        return model\n",
    "\n",
    "    def predict_m(self, kbar, δbar, w, fbar, w_0):\n",
    "        return self.likelihood.predict_m(kbar, δbar, w, fbar, w_0)\n",
    "\n",
    "    def predict_m_with_current(self):\n",
    "        return self.likelihood.predict_m(self.params.kbar.value, \n",
    "                                         self.params.δbar.value, \n",
    "                                         self.params.w.value, \n",
    "                                         self.params.fbar.value,\n",
    "                                         self.params.w_0.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TranscriptionCustom(data, opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples, is_accepted = model.sample(T=300, burn_in=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kbar = model.samples[model.state_indices['kbar']]\n",
    "δbar = model.samples[model.state_indices['δbar']]\n",
    "fbar = model.samples[model.state_indices['fbar']]\n",
    "σ2_m = model.samples[model.state_indices['σ2_m']]\n",
    "rbf_params = model.samples[model.state_indices['rbf_params']]\n",
    "Δbar = model.samples[model.state_indices['Δbar']]\n",
    "print(tf.round(logit(Δbar[-1])))\n",
    "# w = model.samples[model.state_indices['w']][0]\n",
    "# w_0 = model.samples[model.state_indices['w']][1]\n",
    "\n",
    "w = [1*tf.ones((num_genes, num_tfs), dtype='float64')] # TODO\n",
    "w_0 = [tf.zeros(num_genes, dtype='float64')] # TODO\n",
    "\n",
    "pcs = list()\n",
    "for i, param in enumerate(model.state_indices):\n",
    "    if i == 6:\n",
    "        break\n",
    "    pcs.append(tf.reduce_mean(tf.cast(is_accepted[i], dtype=tf.float32)).numpy())\n",
    "\n",
    "display(pd.DataFrame([[f'{100*pc:.02f}%' for pc in pcs]], columns=list(model.state_indices)[:-1]))\n",
    "for i in range(num_tfs):\n",
    "    plt.plot(logit(Δbar[:, i]), label=i)\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(fbar[:, 0, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_preds = list()\n",
    "for i in range(1, 50):\n",
    "    m_preds.append(model.likelihood.predict_m(kbar[-i], δbar[-i], w[-1], fbar[-i], w_0[-1], Δbar[-i])) #todo w[-1]\n",
    "m_preds = np.array(m_preds)\n",
    "\n",
    "f_samples = np.log(1+np.exp(fbar))\n",
    "δ_samples = logit(δbar)\n",
    "k_samples = logit(kbar)\n",
    "rbf_params_samples = [logit(rbf_params[0]), logit(rbf_params[1])] \n",
    "\n",
    "print(true_kbar.shape)\n",
    "true_k = [logit(true_kbar[:,1]).numpy(), logit(true_kbar[:,2]).numpy(), logit(true_kbar[:,3]).numpy()]\n",
    "print(true_k)\n",
    "plotters.generate_report(data, k_samples, δ_samples, f_samples[-100:], σ2_m, rbf_params_samples, m_preds, \n",
    "                         plot_barenco=False, num_hpd=20, true_k=true_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.params\n",
    "def compute_prob(delta):\n",
    "    prob = tf.reduce_sum(model.likelihood.genes(\n",
    "            δbar=params.δbar.value,\n",
    "            kbar=params.kbar.value, \n",
    "            fbar=params.fbar.value, \n",
    "            w=w[-1],\n",
    "            w_0=w_0[-1],\n",
    "            σ2_m=params.σ2_m.value,\n",
    "            Δbar=delta,\n",
    "    ))\n",
    "    prior_prob = model.params.Δbar.prior.log_prob(logit(delta))\n",
    "    print(logit(delta), prior_prob)\n",
    "    print(prob + tf.reduce_sum(prior_prob))\n",
    "    \n",
    "compute_prob(params.Δbar.value)\n",
    "compute_prob(logistic(tf.constant([1, 4, 7.8], dtype='float64')))\n",
    "\n",
    "print(model.params.V.value)\n",
    "print(logistic(1.18), logistic(3.6))\n",
    "print(model.fbar_prior(model.params.fbar.value, f64(0.76), f64(0.97)))\n",
    "print(model.fbar_prior(model.params.fbar.value, f64(0.78), f64(0.98)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit374b75da0e1b40de8b7922d3f142c01d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
