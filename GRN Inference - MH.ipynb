{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p53 network - Metropolis Hastings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from reggae.data_loaders import load_barenco_puma, DataHolder, scaled_barenco_data\n",
    "from reggae.mcmc import create_chains, MetropolisHastings\n",
    "from reggae.models import transcription_mh\n",
    "from reggae.utilities import discretise, inverse_positivity\n",
    "from reggae.plot import plotters\n",
    "from reggae.models import Options\n",
    "from reggae.models.results import GenericResults, SampleResultsMH\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import arviz\n",
    "from multiprocessing import Pool\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df, genes, genes_se, m_observed, f_observed, σ2_m_pre, σ2_f_pre, t = load_barenco_puma()\n",
    "m_observed, f_observed, σ2_m_pre, σ2_f_pre, t = load_barenco_puma()\n",
    "\n",
    "# m_observed, f_observed, t = load_3day_dros()\n",
    "\n",
    "replicate = 0\n",
    "\n",
    "m_df, m_observed = m_observed \n",
    "f_df, f_observed = f_observed\n",
    "\n",
    "data_full = (m_observed, f_observed)\n",
    "\n",
    "# Shape of m_observed = (replicates, genes, times)\n",
    "m_observed = m_observed[replicate]\n",
    "f_observed = np.atleast_2d(f_observed[replicate])\n",
    "σ2_m_pre = σ2_m_pre[0]\n",
    "σ2_f_pre = σ2_f_pre[0]\n",
    "\n",
    "num_genes = m_observed.shape[0]\n",
    "τ, common_indices = discretise(t)\n",
    "N_p = τ.shape[0]\n",
    "N_m = m_observed.shape[1]\n",
    "\n",
    "data = (m_observed, f_observed)\n",
    "noise_data = (σ2_m_pre, σ2_f_pre)\n",
    "time = (t, τ, tf.constant(common_indices))\n",
    "\n",
    "data = DataHolder(data, noise_data, time)\n",
    "opt = Options(preprocessing_variance=True, tf_mrna_present=True)\n",
    "\n",
    "data_full = DataHolder(data_full, noise_data, time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "store_every = 1\n",
    "burn_in = 0\n",
    "report_every = 20\n",
    "num_chains = 4\n",
    "tune_every = 50\n",
    "\n",
    "job = create_chains(\n",
    "    transcription_mh.TranscriptionMCMC, \n",
    "    [data, opt], \n",
    "    {\n",
    "        'T': T, \n",
    "        'store_every': store_every, \n",
    "        'burn_in': burn_in,\n",
    "        'report_every': report_every,\n",
    "        'tune_every':tune_every\n",
    "    }, \n",
    "    num_chains=num_chains)\n",
    "\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = job[0].acceptance_rates.keys()\n",
    "\n",
    "variables = {key : np.empty((0, T, *job[0].samples[key].get().shape[1:])) for key in keys}\n",
    "\n",
    "for res in job:\n",
    "    for key in keys:\n",
    "        variables[key] = np.append(variables[key], np.expand_dims(res.samples[key].get(), 0), axis=0)\n",
    "\n",
    "plt.plot(variables['L'][:,-100:].T)\n",
    "\n",
    "mixes = {key: arviz.convert_to_inference_data(variables[key]) for key in keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rhat\n",
    "Rhat is the ratio of posterior variance and within-chain variance. If the ratio exceeds 1.1 then we consider the chains have not mixed well. As the between-chain variance tends to the within-chain then R tends to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rhat = arviz.rhat(mixes['fbar'])\n",
    "\n",
    "Rhats = np.array([np.mean(arviz.rhat(mixes[key]).x.values) for key in keys])\n",
    "\n",
    "rhat_df = pd.DataFrame([[*Rhats], [*(Rhats < 1.1)]], columns=keys)\n",
    "\n",
    "display(rhat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank plots\n",
    "\n",
    "Rank plots are histograms of the ranked posterior draws (ranked over all\n",
    "    chains) plotted separately for each chain.\n",
    "    If all of the chains are targeting the same posterior, we expect the ranks in each chain to be\n",
    "    uniform, whereas if one chain has a different location or scale parameter, this will be\n",
    "    reflected in the deviation from uniformity. If rank plots of all chains look similar, this\n",
    "    indicates good mixing of the chains.\n",
    "\n",
    "Rank-normalization, folding, and localization: An improved R-hat\n",
    "    for assessing convergence of MCMC. arXiv preprint https://arxiv.org/abs/1903.08008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_rank(mixes['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effective sample sizes\n",
    "\n",
    "Plot quantile, local or evolution of effective sample sizes (ESS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_ess(mixes['L'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monte-Carlo Standard Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_mcse(mixes['L'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Plot\n",
    "Plot parallel coordinates plot showing posterior points with and without divergences.\n",
    "\n",
    "Described by https://arxiv.org/abs/1709.01449, suggested by Ari Hartikainen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_parallel(azl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step size is standard dev, too small means it takes long time to reach high density areas. too long means we reject many of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = job[0].samples\n",
    "acceptance_rates = job[0].acceptance_rates\n",
    "\n",
    "model = transcription_mh.TranscriptionMCMC.initialise_from_state([data, opt], job[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin MCMC\n",
    "model = transcription_mh.TranscriptionMCMC(data, opt)\n",
    "T = 200\n",
    "store_every = 1\n",
    "burn_in = 0\n",
    "report_every = 1\n",
    "\n",
    "model.sample(T, store_every, burn_in, report_every)\n",
    "\n",
    "samples = model.samples\n",
    "parameter_names = model.acceptance_rates.keys()\n",
    "\n",
    "display(pd.DataFrame([[f'{100*samples[\"acc_rates\"][name].get()[-1][0]:.02f}%' for name in parameter_names]], columns=parameter_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## samples = transcription_model.samples\n",
    "plt.figure(figsize=(10,14))\n",
    "parameter_names = model.acceptance_rates.keys()\n",
    "acc_rates = samples['acc_rates']\n",
    "\n",
    "for i, name in enumerate(parameter_names):\n",
    "    plt.subplot(len(parameter_names), 3, i+1)\n",
    "    deltas = acc_rates[name].get()\n",
    "    plt.plot(deltas)\n",
    "    plt.title(name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot transcription ODE kinetic params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "σ2_f = None\n",
    "σ2_m = samples['σ2_m'].get()\n",
    "kbar =   samples['kbar'].get()\n",
    "k_fbar = np.expand_dims(samples['δbar'].get(), [1, 2])\n",
    "fbar =   samples['fbar'].get()\n",
    "kernel_params = [samples[param].get() for param in ['L', 'V']]\n",
    "w =      samples['w'].get()\n",
    "w_0 =    samples['w_0'].get()\n",
    "\n",
    "δbar = samples['δbar'].get()\n",
    "m_preds = list()\n",
    "for i in range(1, 20):\n",
    "    m_preds.append(model.likelihood.predict_m(kbar[-i], δbar[-i], w[-1], fbar[-i], w_0[-1])) #todo w[-1]\n",
    "m_preds = np.expand_dims(np.array(m_preds), 1)\n",
    "\n",
    "fbar = np.expand_dims(fbar, [1, 2])\n",
    "results = SampleResultsMH(fbar, kbar, k_fbar, None, kernel_params, w, w_0, σ2_m, σ2_f)\n",
    "\n",
    "plotters.generate_report(data_full, results, m_preds, plot_barenco=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit374b75da0e1b40de8b7922d3f142c01d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
