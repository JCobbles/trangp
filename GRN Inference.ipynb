{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from collections import namedtuple\n",
    "from ipywidgets import IntProgress\n",
    "# from IPython.display import display\n",
    "\n",
    "import gpflow\n",
    "from gpflow.utilities import print_summary, positive\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import math as tfm\n",
    "from tensorflow_probability import bijectors as tfb\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow_probability import mcmc\n",
    "\n",
    "import arviz\n",
    "\n",
    "from load_puma_data import load_barenco_puma\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "PI = tf.constant(math.pi, dtype='float64')\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, genes, genes_se, Y, Y_var = load_barenco_puma()\n",
    "\n",
    "\n",
    "N_m = 7               # Number of observations\n",
    "def calc_N_p(N_p, num_disc=8):\n",
    "    '''A helper recursive function to ensure t is a subset of τ'''\n",
    "    if num_disc <= 0:\n",
    "        return N_p\n",
    "    return N_p -1 + calc_N_p(N_p, num_disc-1)\n",
    "num_disc = 10\n",
    "N_p = calc_N_p(N_m, num_disc)  # Number of time discretisations\n",
    "common_indices = np.array([i*num_disc+i for i in range(N_m)])\n",
    "t = np.arange(N_m)*2           # Observation times\n",
    "τ = np.linspace(0, 12, N_p, dtype='float64')    # Discretised observation times\n",
    "num_genes = 5\n",
    "I = 1 # Number of TFs\n",
    "\n",
    "m_observed = np.float64(Y[:-1])\n",
    "f_observed = np.float64(np.atleast_2d(Y[-1]))\n",
    "σ2 = np.float64(Y_var[:-1])\n",
    "σ2_f = np.float64(np.atleast_2d(Y_var[-1]))\n",
    "\n",
    "class Parameter():\n",
    "    def __init__(self, prior, initial_value, proposal_dist=None, name=None, constraint=None):\n",
    "        self.name = name\n",
    "        self.prior = prior\n",
    "        self.proposal_dist = proposal_dist\n",
    "        if constraint is None:\n",
    "            self.constrained = lambda x:x\n",
    "        else:\n",
    "            self.constrained = constraint\n",
    "        self.value = initial_value\n",
    "\n",
    "    def set_value(self, value):\n",
    "        this.value = value\n",
    "    def constrain(self, *args):\n",
    "        return self.constrained(*args)\n",
    "    \n",
    "    def propose(self, *args):\n",
    "        assert self.proposal_dist is not None, 'proposal_dist must not be None if you use propose()'\n",
    "        return self.proposal_dist(*args).sample().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis Hastings Custom MCMC Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
    "\n",
    "def get_rbf_dist(times, N):\n",
    "    t_1 = np.reshape(np.tile(times, N), [N, N]).T\n",
    "    t_2 = np.reshape(np.tile(times, N), [N, N])\n",
    "    return t_1-t_2\n",
    "\n",
    "def jitter_cholesky(A):\n",
    "    try:\n",
    "        jitter1 = tf.linalg.diag(1e-7 * np.ones(A.shape[0]))\n",
    "        return tf.linalg.cholesky(A + jitter1)\n",
    "    except:\n",
    "        jitter2 = tf.linalg.diag(1e-5 * np.ones(A.shape[0]))\n",
    "        return tf.linalg.cholesky(A + jitter2)\n",
    "\n",
    "info = np.finfo('float64')\n",
    "def exp(x):\n",
    "    '''Safe exp'''\n",
    "    with np.errstate(under='ignore', over='ignore'):\n",
    "        return np.exp(x)\n",
    "    \n",
    "def mult(a, b):\n",
    "    '''Safe multiplication'''\n",
    "    with np.errstate(under='ignore', over='ignore', invalid='ignore'):\n",
    "        c = a*b\n",
    "        return np.where(np.isnan(c), 0, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.seterr(all='raise')\n",
    "\n",
    "class MetropolisHastings():\n",
    "    '''MH accept function'''\n",
    "    def is_accepted(self, new_log_prob, old_log_prob):\n",
    "        alpha = exp(new_log_prob - old_log_prob)\n",
    "        if tf.is_tensor(alpha):\n",
    "            alpha = alpha.numpy()\n",
    "        return not np.isnan(alpha) and random.random() < min(1, alpha)\n",
    "\n",
    "class TranscriptionLikelihood():\n",
    "    def predict_m(self, kbar, δbar, w, fbar, w_0):\n",
    "        # Take relevant parameters out of log-space\n",
    "        a_j, b_j, d_j, s_j = (np.exp(kbar[:, i]).reshape(-1, 1) for i in range(4))\n",
    "        δ = np.exp(δbar)\n",
    "        f_i = np.log(1+np.exp(fbar))\n",
    "    #     print('f_i', f_i)\n",
    "\n",
    "        # Calculate p_i vector\n",
    "        p_i = np.zeros(N_p) # TODO it seems the ODE translation model has params A, S see gpmtfComputeTFODE\n",
    "        Δ = τ[1]-τ[0]\n",
    "        sum_term = mult(exp(δ*τ), f_i)\n",
    "        p_i[1:] = 0.5*Δ*np.cumsum(sum_term[:-1] + sum_term[1:]) # Trapezoid rule\n",
    "#         try:\n",
    "        p_i = mult(exp(-δ*τ), p_i)\n",
    "#         except:\n",
    "#             print(exp(-δ*τ), p_i)\n",
    "    #     print('pi', p_i)\n",
    "\n",
    "        # Calculate m_pred\n",
    "        integrals = np.zeros((num_genes, N_p))\n",
    "        interactions = w[:, 0][:, None]*np.log(p_i+1e-100) + w_0\n",
    "        G = expit(interactions) # TF Activation Function (sigmoid)\n",
    "        sum_term = G * exp(d_j*τ)\n",
    "        integrals[:, 1:] = 0.5*Δ*np.cumsum(sum_term[:, :-1] + sum_term[:, 1:], axis=1) # Trapezoid rule\n",
    "        exp_dt = exp(-d_j*τ)\n",
    "        integrals = mult(exp_dt, integrals)\n",
    "        m_pred = b_j/d_j + mult((a_j-b_j/d_j), exp_dt) + s_j*integrals\n",
    "\n",
    "        return m_pred\n",
    "\n",
    "    def genes(self, params, δbar=None,\n",
    "                     fbar=None, \n",
    "                     kbar=None, \n",
    "                     w=None,\n",
    "                     σ2_m=None):\n",
    "        '''\n",
    "        Computes likelihood of the genes.\n",
    "        If any of the optional args are None, they are replaced by their current value in params.\n",
    "        '''\n",
    "        if δbar is None:\n",
    "            δbar = params.δbar.value\n",
    "        if fbar is None:\n",
    "            fbar = params.fbar.value\n",
    "        if kbar is None:\n",
    "            kbar = params.kbar.value\n",
    "        w = params.w.value if w is None else w\n",
    "        σ2_m = params.σ2_m.value if σ2_m is None else σ2_m\n",
    "\n",
    "        w_0 = 0 # TODO no hardcode this!\n",
    "        m_pred = self.predict_m(kbar, δbar, w, fbar, w_0)\n",
    "\n",
    "        log_lik = np.zeros(num_genes)\n",
    "        sq_diff = np.square(m_observed - m_pred[:, common_indices])\n",
    "        variance = σ2_m.reshape(-1, 1) + σ2 # add PUMA variance\n",
    "        log_lik = -0.5*np.log(2*np.pi*(variance)) - 0.5*sq_diff/variance\n",
    "        log_lik = np.sum(log_lik, axis=1)\n",
    "\n",
    "        return log_lik\n",
    "\n",
    "    def tfs(self, fbar, i=0): \n",
    "        '''\n",
    "        Computes log-likelihood of the transcription factors.\n",
    "        TODO this should be for the i-th TF\n",
    "        '''\n",
    "        f_pred = np.log(1+np.exp(fbar))\n",
    "        f_pred = np.atleast_2d(f_pred[common_indices])\n",
    "        sq_diff = np.square(f_observed[i] - f_pred[i])\n",
    "        log_lik = -0.5*sum(np.log(2*np.pi*σ2_f[i])) - 0.5*sum(sq_diff/σ2_f[i])\n",
    "        return log_lik\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f64 = np.float64\n",
    "class TranscriptionMCMC(MetropolisHastings):\n",
    "    def __init__(self):\n",
    "        self.likelihood = TranscriptionLikelihood()\n",
    "        self.clear_samples()\n",
    "        # Adaptable variances\n",
    "        a = tf.constant(-0.5, dtype='float64')\n",
    "        b2 = tf.constant(2., dtype='float64')\n",
    "        self.h_δ = 0.25\n",
    "        self.h_c = 0.05\n",
    "        self.h_f = 0.35*tf.ones(N_p, dtype='float64')\n",
    "        self.h_k = 0.25*tf.ones(4, dtype='float64')\n",
    "        self.h_w = 0.5*tf.ones(num_genes, dtype='float64')\n",
    "        h_σm = tf.constant(0.5, dtype='float64')\n",
    "\n",
    "        # Interaction weights\n",
    "        w_0 = Parameter(tfd.Normal(0, 2), np.zeros(num_genes), proposal_dist=lambda mu, j:tfd.Normal(mu, self.h_w[j]))\n",
    "        w = Parameter(\n",
    "            tfd.Normal(0, 2), \n",
    "            1*np.ones((num_genes, I)), # IT WAS 0.1\n",
    "            proposal_dist=lambda mu, j:tfd.Normal(mu, self.h_w[j])) #) w_j) # At the moment this is the same as w_j0 (see pg.8)\n",
    "        # Latent function\n",
    "        fbar = Parameter(self.fbar_prior, 0.5*np.ones(N_p))\n",
    "\n",
    "        # GP hyperparameters\n",
    "        V = Parameter(tfd.InverseGamma(f64(0.01), f64(0.01)), f64(1), \n",
    "                      proposal_dist=lambda v: tfd.TruncatedNormal(v, self.h_c, low=0, high=100)) #v_i Fix to 1 if translation model is not used (pg.8)\n",
    "        L = Parameter(tfd.Uniform(f64(4), f64(144)), f64(4),\n",
    "                      proposal_dist=lambda l2: tfd.TruncatedNormal(l2, self.h_c, low=0, high=100)) #l2_i\n",
    "        self.t_dist = get_rbf_dist(τ, N_p)\n",
    "\n",
    "        # Translation kinetic parameters\n",
    "        δbar = Parameter(tfd.Normal(a, b2), f64(-0.3), proposal_dist=lambda mu:tfd.Normal(mu, self.h_δ))\n",
    "        # White noise for genes\n",
    "        σ2_m = Parameter(tfd.InverseGamma(f64(0.01), f64(0.01)), 1e-4*np.ones(num_genes),\n",
    "                         proposal_dist=lambda mu: tfd.TruncatedNormal(mu, h_σm, low=0, high=5))\n",
    "        # Transcription kinetic parameters\n",
    "        def constrain_kbar(kbar, gene):\n",
    "            '''Constrains a given row in kbar'''\n",
    "#             if gene == 3:\n",
    "#                 kbar[2] = np.log(0.8)\n",
    "#                 kbar[3] = np.log(1.0)\n",
    "            kbar[kbar < -10] = -10\n",
    "            kbar[kbar > 2] = 2\n",
    "            return kbar\n",
    "        kbar_initial = -0.1*np.float64(np.c_[\n",
    "            np.ones(num_genes), # a_j\n",
    "            np.ones(num_genes), # b_j\n",
    "            np.ones(num_genes), # d_j\n",
    "            np.ones(num_genes)  # s_j\n",
    "        ])\n",
    "        for j, k in enumerate(kbar_initial):\n",
    "            kbar_initial[j] = constrain_kbar(k, j)\n",
    "        kbar = Parameter(\n",
    "            tfd.Normal(a, b2), \n",
    "            kbar_initial,\n",
    "            proposal_dist=lambda mu: tfd.MultivariateNormalDiag(mu, self.h_k),\n",
    "            constraint=constrain_kbar)\n",
    "        params = namedtuple('parameters', ['fbar','δbar','kbar','σ2_m','w','w_0','L','V'])\n",
    "        self.params = params(fbar, δbar, kbar, σ2_m, w, w_0, L, V)\n",
    "        \n",
    "    def fbar_prior_params(self, v, l2):\n",
    "    #     print('vl2', v, l2)\n",
    "        jitter = tf.linalg.diag(1e-5 * np.ones(N_p))\n",
    "        K = mult(v, exp(-np.square(self.t_dist)/(2*l2))) + jitter\n",
    "        m = np.zeros(N_p)\n",
    "        return m, K\n",
    "\n",
    "    def fbar_prior(self, fbar, v, l2):\n",
    "        m, K = self.fbar_prior_params(v, l2)\n",
    "    \n",
    "        try:\n",
    "            return tfd.MultivariateNormalFullCovariance(m, K).log_prob(fbar)\n",
    "        except:\n",
    "            jitter = tf.linalg.diag(1e-4 * np.ones(N_p))\n",
    "            try:\n",
    "                return np.float64(tfd.MultivariateNormalFullCovariance(m, K+jitter).log_prob(fbar))\n",
    "            except:\n",
    "                return 0\n",
    "\n",
    "    def clear_samples(self):\n",
    "        self.samples = {\n",
    "            'δbar': list(), \n",
    "            'kbar': [list() for _ in range(num_genes)],\n",
    "            'σ2_m': [list() for _ in range(num_genes)],\n",
    "            'w': [list() for _ in range(num_genes)],\n",
    "            'w_0': [list() for _ in range(num_genes)],\n",
    "            'L': list(),\n",
    "            'V': list(),\n",
    "            'fbar': list(),\n",
    "            'acc_rates': list()\n",
    "        }\n",
    "        \n",
    "    def adapt(self):\n",
    "        T = 5\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i, h_δ_test in enumerate(np.linspace(0.1, 0.25, T)):\n",
    "            self.clear_samples()\n",
    "            self.h_δ = h_δ_test\n",
    "            plt.subplot(T, 3, i+1)\n",
    "            self.sample(T=300, store_every=1, burn_in=0, report_every=200) # sample, do not report\n",
    "            plt.acorr(self.samples['δbar'], maxlags=50)\n",
    "            plt.tight_layout()\n",
    "            plt.xlim(-1, 50)\n",
    "            plt.title(f'h_δ = {h_δ_test:3f}')\n",
    "            print(self.acceptance_rates)\n",
    "        \n",
    "        # Selecting...\n",
    "        self.h_δ = 0.30\n",
    "        self.clear_samples()\n",
    "        self.sample(T=1000, store_every=1, burn_in=0)\n",
    "#         plt.plot(self.samples['acceptance_rates']['δ'])\n",
    "    \n",
    "    def sample(self, T=20000, store_every=10, burn_in=1000, report_every=100):\n",
    "        print('----- Metropolis Begins -----')\n",
    "        self.acceptance_rates = { # Reset acceptance rates\n",
    "            'f': 0.,\n",
    "            'δ': 0.,\n",
    "            'k': 0.,\n",
    "            'σ': 0.,\n",
    "            'w': 0.,\n",
    "            'L': 0.,\n",
    "            'V': 0.\n",
    "        }\n",
    "        f = IntProgress(description='Running', min=0, max=T) # instantiate the bar\n",
    "        display(f)\n",
    "        for iteration_number in range(T):\n",
    "            if iteration_number % report_every == 0:\n",
    "                f.value = iteration_number \n",
    "#                 print(f'{100*iteration_number/T:.2f}% complete', end='\\r')\n",
    "\n",
    "            self.iterate()\n",
    "    \n",
    "            if iteration_number >= burn_in and iteration_number % store_every == 0:\n",
    "                for j in range(num_genes):\n",
    "                    self.samples['σ2_m'][j].append(self.params.σ2_m.value[j].copy())\n",
    "                    self.samples['w'][j].append(self.params.w.value[j].copy())\n",
    "                    self.samples['kbar'][j].append(self.params.kbar.value[j].copy())\n",
    "                    self.samples['w_0'][j].append(self.params.w_0.value[j])\n",
    "\n",
    "                self.samples['V'].append(self.params.V.value)\n",
    "                self.samples['L'].append(self.params.L.value)\n",
    "                self.samples['δbar'].append(self.params.δbar.value)\n",
    "                self.samples['fbar'].append(self.params.fbar.value)\n",
    "                self.samples['acc_rates'].append(list(self.acceptance_rates.values()))\n",
    "                \n",
    "        for key in self.acceptance_rates:\n",
    "            self.acceptance_rates[key] /= T\n",
    "        f.value = T\n",
    "        print('----- Finished -----')\n",
    "\n",
    "    def iterate(self):\n",
    "        params = self.params\n",
    "        # Compute likelihood for comparison\n",
    "        old_m_likelihood = self.likelihood.genes(params)\n",
    "        \n",
    "        # Untransformed tf mRNA vectors F\n",
    "        fbar = params.fbar.value\n",
    "        for i in range(I):\n",
    "            # Gibbs step\n",
    "            z_i = tf.reshape(tfd.MultivariateNormalDiag(fbar, self.h_f).sample(), (1, -1))\n",
    "            # MH\n",
    "            m, K = self.fbar_prior_params(params.V.value, params.L.value)\n",
    "            invKsigmaK = tf.matmul(tf.linalg.inv(K+tf.linalg.diag(self.h_f)), K) # (C_i + hI)C_i\n",
    "            L = jitter_cholesky(K-tf.matmul(K, invKsigmaK))\n",
    "            c_mu = tf.matmul(z_i, invKsigmaK)\n",
    "            fstar = tf.matmul(tf.random.normal((1, L.shape[0]), dtype='float64'), L) + c_mu\n",
    "            fstar = tf.reshape(fstar, (-1, ))\n",
    "            new_m_likelihood = self.likelihood.genes(params, fbar=fstar)\n",
    "            new_prob = np.sum(new_m_likelihood) + self.likelihood.tfs(fstar)\n",
    "            old_prob = np.sum(old_m_likelihood) + self.likelihood.tfs(fbar)\n",
    "            if self.is_accepted(new_prob, old_prob):\n",
    "                params.fbar.value = fstar\n",
    "                old_m_likelihood = new_m_likelihood\n",
    "                self.acceptance_rates['f'] += 1/I\n",
    "\n",
    "\n",
    "        # Log of translation ODE degradation rates\n",
    "        δbar = params.δbar.value\n",
    "        for i in range(I):# TODO make for I > 1\n",
    "            # Proposal distribution\n",
    "            δstar = params.δbar.propose(δbar) # δstar is in log-space, i.e. δstar = δbar*\n",
    "            new_prob = np.sum(self.likelihood.genes(params, δbar=δstar)) + params.δbar.prior.log_prob(δstar)\n",
    "            old_prob = np.sum(old_m_likelihood) + params.δbar.prior.log_prob(δbar)\n",
    "#             print(δstar, params.δbar.prior.log_prob(δstar))\n",
    "#             print(new_prob, old_prob)\n",
    "            if self.is_accepted(new_prob, old_prob):\n",
    "                params.δbar.value = δstar\n",
    "                self.acceptance_rates['δ'] += 1/I\n",
    "\n",
    "        # Log of transcription ODE kinetic params\n",
    "        kbar = params.kbar.value\n",
    "        kstar = kbar.copy()\n",
    "        for j in range(num_genes):\n",
    "            sample = params.kbar.propose(kstar[j])\n",
    "            sample = params.kbar.constrain(sample, j)\n",
    "\n",
    "            kstar[j] = sample\n",
    "            new_prob = self.likelihood.genes(params, kbar=kstar)[j] + sum(params.kbar.prior.log_prob(sample))\n",
    "            old_prob = old_m_likelihood[j] + sum(params.kbar.prior.log_prob(kbar[j]))\n",
    "            if self.is_accepted(new_prob, old_prob):\n",
    "                test = params.kbar.value\n",
    "                test[j]=sample\n",
    "                params.kbar.value = test\n",
    "                self.acceptance_rates['k'] += 1/num_genes\n",
    "            else:\n",
    "                kstar[j] = params.kbar.value[j]\n",
    "\n",
    "\n",
    "        # Interaction weights and biases (note: should work for I > 1)\n",
    "        w = params.w.value\n",
    "        w_0 = params.w_0.value\n",
    "        wstar = w.copy()\n",
    "        for j in range(num_genes):\n",
    "            sample_0 = params.w_0.propose(w_0[j], j)\n",
    "            sample = params.w.propose(wstar[j], j)\n",
    "            wstar[j] = sample\n",
    "            new_prob = self.likelihood.genes(params, w=wstar)[j] + sum(params.w.prior.log_prob(sample)) + params.w_0.prior.log_prob(sample_0)\n",
    "            old_prob = old_m_likelihood[j] + sum(params.w.prior.log_prob(w[j,:])) + params.w_0.prior.log_prob(w_0[j])\n",
    "            if self.is_accepted(new_prob, old_prob):\n",
    "                params.w.value[j] = sample\n",
    "                params.w_0.value[j] = sample_0\n",
    "                self.acceptance_rates['w'] += 1/num_genes\n",
    "            else:\n",
    "                wstar[j] = params.w.value[j]\n",
    "\n",
    "        # Noise variances\n",
    "        σ2_m = params.σ2_m.value\n",
    "        σ2_mstar = σ2_m.copy()\n",
    "        for j in range(num_genes):\n",
    "            sample = params.σ2_m.propose(σ2_m[j])\n",
    "            σ2_mstar[j] = sample\n",
    "            old_q = params.σ2_m.proposal_dist(σ2_mstar[j]).log_prob(σ2_m[j])\n",
    "            new_prob = self.likelihood.genes(params, σ2_m=σ2_mstar)[j] +params.σ2_m.prior.log_prob(σ2_mstar[j])\n",
    "            \n",
    "            new_q = params.σ2_m.proposal_dist(σ2_m[j]).log_prob(σ2_mstar[j])\n",
    "            old_prob = self.likelihood.genes(params, σ2_m=σ2_m)[j] + params.σ2_m.prior.log_prob(σ2_m[j])\n",
    "                \n",
    "            if self.is_accepted(new_prob + old_q, old_prob + new_q):\n",
    "                params.σ2_m.value[j] = sample\n",
    "                self.acceptance_rates['σ'] += 1/num_genes\n",
    "            else:\n",
    "                σ2_mstar[j] = σ2_m[j]\n",
    "\n",
    "        # Length scales and variances of GP kernels\n",
    "        l2 = params.L.value\n",
    "        v = params.V.value\n",
    "        for i in range(I):\n",
    "            # Proposal distributions\n",
    "            Q_v = params.V.proposal_dist\n",
    "            Q_l = params.L.proposal_dist\n",
    "            vstar = params.V.propose(v)\n",
    "            l2star = params.L.propose(l2)\n",
    "#             print(vstar, l2star)# 'prior', fbar_prior(fbar_i, vstar, l2star))\n",
    "            # Acceptance probabilities\n",
    "            new_fbar_prior = params.fbar.prior(params.fbar.value, vstar, l2star)\n",
    "            old_q = Q_v(vstar).log_prob(v) + Q_l(l2star).log_prob(l2) # Q(old|new)\n",
    "            new_prob = new_fbar_prior + params.V.prior.log_prob(vstar) + params.L.prior.log_prob(l2star)\n",
    "            \n",
    "            new_q = Q_v(v).log_prob(vstar) + Q_l(l2).log_prob(l2star) # Q(new|old)\n",
    "            old_prob = params.fbar.prior(params.fbar.value, v, l2) + params.V.prior.log_prob(v) + params.L.prior.log_prob(l2)\n",
    "#self.old_fbar_prior\n",
    "            accepted = self.is_accepted(new_prob + old_q, old_prob + new_q)\n",
    "            if accepted:\n",
    "#                 print(\"accepted\")\n",
    "                params.V.value = vstar\n",
    "                params.L.value = l2star\n",
    "#                 print(new_fbar_prior, self.old_fbar_prior)\n",
    "\n",
    "#                 self.old_fbar_prior = new_fbar_prior\n",
    "                self.acceptance_rates['V'] += 1/I\n",
    "                self.acceptance_rates['L'] += 1/I\n",
    "\n",
    "    def predict_m(self):\n",
    "        return self.likelihood.predict_m(self.params.kbar.value, \n",
    "                                         self.params.δbar.value, \n",
    "                                         self.params.w.value, \n",
    "                                         self.params.fbar.value, 0)\n",
    "\n",
    "transcription_model = TranscriptionMCMC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin MCMC Adaptive phase\n",
    "transcription_model.adapt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin MCMC\n",
    "T = 2000\n",
    "store_every = 1\n",
    "burn_in = 0\n",
    "report_every = 20\n",
    "\n",
    "transcription_model.sample(T, store_every, burn_in, report_every)\n",
    "\n",
    "print(transcription_model.acceptance_rates)\n",
    "\n",
    "samples = transcription_model.samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step size is standard dev, too small means it takes long time to reach high density areas. too long means we reject many of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## samples = transcription_model.samples\n",
    "\n",
    "plt.figure(figsize=(10,14))\n",
    "parameter_names = transcription_model.acceptance_rates.keys()\n",
    "acc_rates = np.array(samples['acc_rates'])\n",
    "\n",
    "for i, name in enumerate(parameter_names):\n",
    "    plt.subplot(len(parameter_names), 3, i+1)\n",
    "    deltas = acc_rates[acc_rates.shape[0]-T:, i]/np.arange(1, T-burn_in+1, store_every)\n",
    "    plt.plot(deltas)\n",
    "    plt.title(name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decay\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, param in enumerate(['δbar', 'L', 'V']):\n",
    "    ax = plt.subplot(331+i)\n",
    "    plt.plot(samples[param])\n",
    "    ax.set_title(param)\n",
    "#'σ', 'w']):\n",
    "\n",
    "plt.figure()\n",
    "for j in range(num_genes):\n",
    "    plt.plot(samples['w'][j], label=df.index[j])\n",
    "plt.legend()\n",
    "    \n",
    "plt.title('Interaction weights')\n",
    "\n",
    "plt.figure()\n",
    "for j in range(num_genes):\n",
    "    plt.plot(samples['w_0'][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot transcription ODE kinetic params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "plt.title('Transcription ODE kinetic parameters')\n",
    "labels = ['a', 'b', 'd', 's']\n",
    "for j in range(num_genes):\n",
    "    ax = plt.subplot(num_genes, 2, j+1)\n",
    "    k_param = np.array(samples['kbar'][j])\n",
    "#     print(k_param)\n",
    "    \n",
    "    for k in range(4):\n",
    "        plt.plot(k_param[-20000:, k], label=labels[k])\n",
    "    plt.axhline(np.mean(k_param[-20000:, 3]))\n",
    "    plt.legend()\n",
    "    ax.set_title(f'Gene {j}')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "kbar = samples['kbar']\n",
    "def plot_kinetics(kbar):\n",
    "    plt.figure(figsize=(14, 14))\n",
    "    k_latest = np.exp(np.array([\n",
    "        np.mean(np.array(kbar[j])[-5000:], axis=0) for j in range(num_genes)]))\n",
    "    print(k_latest)\n",
    "    B = k_latest[:,1]\n",
    "    D = k_latest[:,2]\n",
    "    S = k_latest[:,3]\n",
    "    print(B)\n",
    "    B_barenco = np.array([2.6, 1.5, 0.5, 0.2, 1.35])# From Martino paper ... but don't know the scale\n",
    "    B_barenco = B_barenco/np.mean(B_barenco)*np.mean(B)# do a rough rescaling so that the scales match.\n",
    "    S_barenco = np.array([3, 0.8, 0.7, 1.8, 0.7])/1.8\n",
    "    D_barenco = np.array([1.2, 1.6, 1.75, 3.2, 2.3])*0.8/3.2\n",
    "\n",
    "\n",
    "    data = [B, S, D]\n",
    "    barenco_data = [B_barenco, S_barenco, D_barenco]\n",
    "    labels = ['Basal rates', 'Sensitivities', 'Decay rates']\n",
    "\n",
    "    plotnum = 331\n",
    "    for A, B, label in zip(data, barenco_data, labels):\n",
    "        plt.subplot(plotnum)\n",
    "        plotnum+=1\n",
    "        plt.bar(np.arange(5)-0.2, A, width=0.4, tick_label=df.index[:-1])\n",
    "        plt.bar(np.arange(5)+0.2, B, width=0.4, color='blue', align='center')\n",
    "\n",
    "        plt.title(label)\n",
    "plot_kinetics(kbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot genes\n",
    "plt.figure(figsize=(14, 17))\n",
    "m_pred = transcription_model.predict_m()\n",
    "print(2000000*np.sqrt(Y_var[1]))\n",
    "for j in range(num_genes):\n",
    "    ax = plt.subplot(531+j)\n",
    "    plt.title(df.index[j])\n",
    "    plt.scatter([n*10+n for n in range(7)], m_observed[j], marker='x')\n",
    "    plt.errorbar([n*10+n for n in range(7)], Y[j], 2*np.sqrt(Y_var[j]), fmt='none', capsize=5)\n",
    "    plt.plot(m_pred[j,:], color='grey')\n",
    "    plt.xticks(np.arange(N_p)[common_indices])\n",
    "    ax.set_xticklabels(np.arange(N_m)*2)\n",
    "    plt.xlabel('Time (h)');\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.title('Noise variances')\n",
    "for i, j in enumerate(range(num_genes)):\n",
    "    ax = plt.subplot(num_genes, num_genes-2, i+1)\n",
    "    plt.title(df.index[j])\n",
    "    plt.plot(samples['σ2_m'][j]);\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_barenco_data(f):\n",
    "    scale_pred = np.sqrt(np.var(f))\n",
    "    barencof = np.array([[0.0, 200.52011, 355.5216125, 205.7574913, 135.0911372, 145.1080997, 130.7046969],\n",
    "                         [0.0, 184.0994134, 308.47592, 232.1775328, 153.6595161, 85.7272235, 168.0910562],\n",
    "                         [0.0, 230.2262511, 337.5994811, 276.941654, 164.5044287, 127.8653452, 173.6112139]])\n",
    "\n",
    "    barencof = barencof[0]/(np.sqrt(np.var(barencof[0])))*scale_pred\n",
    "    measured_p53 = df[df.index.isin(['211300_s_at', '201746_at'])]\n",
    "    measured_p53 = measured_p53.mean(0)\n",
    "    measured_p53 = measured_p53*scale_pred\n",
    "    \n",
    "    return barencof, measured_p53\n",
    "\n",
    "def plot_f(f):\n",
    "    fig = plt.figure(figsize=(13, 7))\n",
    "\n",
    "    barencof = scaled_barenco_data(f)\n",
    "    lb = len(barencof)\n",
    "    print(lb)\n",
    "    plt.plot(np.arange(N_p), f, color='grey')\n",
    "    plt.scatter(np.arange(0, N_p)[common_indices], barencof, marker='x')\n",
    "    plt.xticks(np.arange(N_p)[common_indices])\n",
    "    fig.axes[0].set_xticklabels(np.arange(N_m)*2)\n",
    "    plt.xlabel('Time (h)');\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 7))\n",
    "f_samples = np.log(1+np.exp(np.array(samples['fbar'][-50:])))\n",
    "\n",
    "bounds = arviz.hpd(f_samples, credible_interval=0.95)\n",
    "\n",
    "for i in range(1,20):\n",
    "    f_i = f_samples[-i]\n",
    "#     plt.plot(f_i)\n",
    "#     f_i[0] = 0\n",
    "    plt.plot(f_i, c='blue', alpha=0.5)\n",
    "\n",
    "    \n",
    "barenco_f, _ = scaled_barenco_data(f_samples[-1])\n",
    "plt.scatter(np.arange(N_p)[common_indices], barenco_f, marker='x', s=60, linewidth=3, label='Barenco')\n",
    "plt.scatter(np.arange(N_p)[common_indices], f_observed[0], marker='x', s=60, linewidth=3, label='Observed')\n",
    "plt.errorbar(np.arange(N_p)[common_indices], f_observed[0], 2*np.sqrt(σ2_f[0]), fmt='none', capsize=5, color='blue')\n",
    "\n",
    "plt.fill_between(np.arange(N_p), bounds[:, 0], bounds[:, 1], color='grey', alpha=0.5)\n",
    "plt.xticks(np.arange(N_p)[common_indices])\n",
    "fig.axes[0].set_xticklabels(np.arange(N_m)*2)\n",
    "plt.xlabel('Time (h)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = np.log(1+np.exp(transcription_model.params.fbar.value))\n",
    "f_i[0] = 0\n",
    "plot_f(f_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_observed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit374b75da0e1b40de8b7922d3f142c01d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}