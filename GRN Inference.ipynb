{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import gpflow\n",
    "from gpflow.utilities import print_summary, positive\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import math as tfm\n",
    "from tensorflow_probability import bijectors as tfb\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow_probability import mcmc\n",
    "\n",
    "from load_puma_data import load_barenco_puma\n",
    "import math\n",
    "import random\n",
    "\n",
    "PI = tf.constant(math.pi, dtype='float64')\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, genes, genes_se, Y, Y_var = load_barenco_puma()\n",
    "\n",
    "\n",
    "N_m = 7               # Number of observations\n",
    "def calc_N_p(N_p, num_disc=8):\n",
    "    '''A helper recursive function to ensure t is a subset of τ'''\n",
    "    if num_disc <= 0:\n",
    "        return N_p\n",
    "    return N_p -1 + calc_N_p(N_p, num_disc-1)\n",
    "num_disc = 10\n",
    "N_p = calc_N_p(N_m, num_disc)  # Number of time discretisations\n",
    "common_indices = np.array([i*num_disc+i for i in range(N_m)])\n",
    "t = np.arange(N_m)*2           # Observation times\n",
    "τ = np.linspace(0, 12, N_p, dtype='float32')    # Discretised observation times\n",
    "num_genes = 5\n",
    "I = 1 # Number of TFs\n",
    "\n",
    "m_observed = np.float32(Y[:-1])\n",
    "f_observed = np.float32(np.atleast_2d(Y[-1]))\n",
    "σ2 = np.float32(Y_var[:-1])\n",
    "σ2_f = np.float32(np.atleast_2d(Y_var[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis Hastings Custom MCMC Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MH acceptance\n",
    "def is_accepted(new_log_prob, old_log_prob):\n",
    "    alpha = np.exp(new_log_prob - old_log_prob)\n",
    "    if tf.is_tensor(alpha):\n",
    "        alpha = alpha.numpy()\n",
    "    return not np.isnan(alpha) and random.random() < min(1, alpha)\n",
    "\n",
    "# Parameters\n",
    "params = None\n",
    "w_j0 = 0    # Interaction bias (TODO)\n",
    "w_j = 0.1*np.ones((num_genes, I), dtype='float32')\n",
    "fbar_i = 0.5*np.ones(N_p, dtype='float32')\n",
    "v_i = 1 # Fix this to 1 if translation model is not used (pg.8)\n",
    "l2_i = 0.1\n",
    "δbar_i = np.float32(-0.3)\n",
    "h_δ = 0.05\n",
    "h_c = 0.3\n",
    "h_f = 0.4*tf.ones(N_p, dtype='float32')\n",
    "h_k = 0.05*tf.ones(4, dtype='float32')\n",
    "h_w = tf.ones(num_genes, dtype='float32')\n",
    "h_σm = tf.constant(0.8, dtype='float32')\n",
    "a = tf.constant(-0.5, dtype='float32')\n",
    "b2 = tf.constant(2., dtype='float32')\n",
    "σ2_m = 1e-2*np.ones(num_genes, dtype='float32')\n",
    "kbar_i = -0.1*np.float32(np.c_[np.ones(num_genes), # a_j\n",
    "                          np.ones(num_genes), # b_j\n",
    "                          np.ones(num_genes), # d_j\n",
    "                          np.ones(num_genes)])# s_j\n",
    "def fixed(kbar, gene):\n",
    "    if gene == 3:\n",
    "        kbar[2] = np.log(0.8)\n",
    "        kbar[3] = np.log(1.0)\n",
    "    kbar[kbar < -10] = -10\n",
    "    kbar[kbar > 2] = 2\n",
    "    return kbar\n",
    "kbar_i[3] = fixed(kbar_i[3], 3)\n",
    "print(kbar_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
    "\n",
    "def get_rbf_dist(times, N):\n",
    "    t_1 = np.reshape(np.tile(times, N), [N, N]).T\n",
    "    t_2 = np.reshape(np.tile(times, N), [N, N])\n",
    "    return t_1-t_2\n",
    "\n",
    "# Priors\n",
    "def l2_prior(l2):\n",
    "    return tfd.InverseGamma(0.1, 0.1).log_prob(l2) # TODO\n",
    "def v_prior(v):\n",
    "    return tfd.InverseGamma(0.1, 0.1).log_prob(v)\n",
    "def σ2_m_prior(σ):\n",
    "    return tfd.InverseGamma(0.01, 0.01).log_prob(σ)\n",
    "\n",
    "def w_j_prior(w_j): # At the moment this is the same as w_j0 (see pg.8)\n",
    "    return tfd.Normal(0, 2).log_prob(w_j)\n",
    "def w_j0_prior(w_j0):\n",
    "    return tfd.Normal(0, 2).log_prob(w_j0)\n",
    "    \n",
    "def kbar_prior(kbar):\n",
    "    return tfd.Normal(a, b2).log_prob(kbar)\n",
    "\n",
    "def fbar_prior_params(v=v_i, l2=l2_i):\n",
    "    t_dist = get_rbf_dist(τ, N_p)\n",
    "#     print('vl2', v, l2)\n",
    "    jitter = tf.linalg.diag(1e-5 * np.ones(N_p, dtype='float32'))\n",
    "    K = v * np.exp(-np.square(t_dist)/(2*l2)) + jitter\n",
    "#     print(K)\n",
    "    m = np.zeros(N_p, dtype='float32')\n",
    "    return m, K\n",
    "\n",
    "def fbar_prior(fbar, v=v_i, l2=l2_i):\n",
    "    m, K = fbar_prior_params(v, l2)\n",
    "    try:\n",
    "        prob = np.float64(tfd.MultivariateNormalFullCovariance(m, K).prob(fbar))\n",
    "        return prob\n",
    "    except:\n",
    "        jitter = tf.linalg.diag(1e-4 * np.ones(N_p, dtype='float32'))\n",
    "        try:\n",
    "            prob = np.float64(tfd.MultivariateNormalFullCovariance(m, K+jitter).log_prob(fbar))\n",
    "            return prob\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "def δbar_prior(δ):\n",
    "    return tfd.Normal(a, b2).log_prob(δ)\n",
    "\n",
    "# Likelihoods\n",
    "def predict_m(kbar, δbar, w, fbar):\n",
    "    # Take relevant parameters out of log-space\n",
    "    a_j, b_j, d_j, s_j = (np.exp(kbar_i[:, i]).reshape(-1, 1) for i in range(4))\n",
    "    δ = np.exp(δbar)\n",
    "    f_i = np.log(1+np.exp(fbar))\n",
    "#     print('f_i', f_i)\n",
    "\n",
    "    # Calculate p_i vector\n",
    "    p_i = np.zeros(N_p) # TODO it seems the ODE translation model has params A, S see gpmtfComputeTFODE\n",
    "    Δ = τ[1]-τ[0]\n",
    "    sum_term = np.exp(δ*τ) * f_i\n",
    "    p_i[1:] = 0.5*Δ*np.cumsum(sum_term[:-1] + sum_term[1:]) # Trapezoid rule\n",
    "    p_i = np.exp(-δ*τ) * p_i\n",
    "\n",
    "#     print('pi', p_i)\n",
    "\n",
    "    # Calculate m_pred\n",
    "    integrals = np.zeros((num_genes, N_p), dtype='float32')\n",
    "    interactions = w_j[:, 0][:, None]*np.log(p_i+1e-50) + w_j0    \n",
    "    G = 1/(1+np.exp(-interactions)) # TF Activation Function\n",
    "    sum_term = G * np.exp(d_j*τ)\n",
    "    integrals[:, 1:] = 0.5*Δ*np.cumsum(sum_term[:, :-1] + sum_term[:, 1:], axis=1) # Trapezoid rule\n",
    "    exp_dt = np.exp(-d_j*τ)\n",
    "    integrals = exp_dt * integrals\n",
    "    m_pred = b_j/d_j + (a_j-b_j/d_j)*exp_dt + s_j*integrals\n",
    "\n",
    "    return m_pred\n",
    "\n",
    "def m_likelihood(δbar=None, \n",
    "                 fbar=None, \n",
    "                 kbar=None, \n",
    "                 w=None,\n",
    "                 σ=None,\n",
    "                 changed=True):\n",
    "    if δbar is None:\n",
    "        δbar = δbar_i\n",
    "    if fbar is None:\n",
    "        fbar = fbar_i\n",
    "    if kbar is None:\n",
    "        kbar = kbar_i\n",
    "    if w is None:\n",
    "        w = w_j\n",
    "    if σ is None:\n",
    "        σ = σ2_m\n",
    "\n",
    "    m_pred = predict_m(kbar, δbar, w, fbar)\n",
    "    \n",
    "    log_lik = np.zeros(num_genes)\n",
    "    sq_diff = np.square(m_observed - m_pred[:, common_indices])\n",
    "    variance = σ2_m.reshape(-1, 1) + σ2 # add PUMA variance\n",
    "    log_lik = -0.5*np.log(2*np.pi*(variance)) - 0.5*sq_diff/variance\n",
    "    log_lik = np.sum(log_lik, axis=1)\n",
    "    \n",
    "#     t_dist = get_rbf_dist(t, N_m)        # RBF covariance\n",
    "#     jitter = tf.linalg.diag(1e-5 * np.ones(N_m, dtype='float32'))\n",
    "#     K = 1 * np.exp(-np.square(t_dist)/(2*1)) + jitter # TODO replace v, l2\n",
    "#     for j in range(num_genes):\n",
    "#         K_j = K + tf.linalg.diag(σ2[j])\n",
    "#         L = tf.linalg.cholesky(K_j)\n",
    "#         d = diff[j][:, None]\n",
    "#         alpha = tf.linalg.triangular_solve(L, d, lower=True)\n",
    "#         num_dims = tf.cast(tf.shape(d)[0], L.dtype)\n",
    "#         p = -0.5 * tf.reduce_sum(tf.square(alpha), 0)\n",
    "#         p -= 0.5 * num_dims * np.log(2 * np.pi)\n",
    "#         p -= tf.reduce_sum(tf.math.log(tf.linalg.diag_part(L)))\n",
    "#         lik[j] = p\n",
    "    \n",
    "    return log_lik\n",
    "\n",
    "def f_likelihood(fbar, i=0): \n",
    "    '''TODO this should be for the i-th TF'''\n",
    "    f_i = np.log(1+np.exp(fbar))\n",
    "    f_i = np.float32(np.atleast_2d(f_i[common_indices]))\n",
    "#     print(f_i[i], f[i])\n",
    "    prob = tfd.Normal(f_observed[i], σ2_f[i]).log_prob(f_i[i])\n",
    "#     print('prob', prob)\n",
    "    lik = tf.reduce_sum(prob)\n",
    "    return lik\n",
    "\n",
    "old_m_likelihood = None\n",
    "old_m_likelihood = m_likelihood(changed=True)\n",
    "print(old_m_likelihood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w_j[4, :])\n",
    "w_j_prior(w_j[4, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbar_i = 0*np.float32(np.c_[np.ones(num_genes), # a_j\n",
    "                          np.ones(num_genes), # b_j\n",
    "                          np.ones(num_genes), # d_j\n",
    "                          np.ones(num_genes)])# s_j\n",
    "for j in range(num_genes):\n",
    "    kbar_i[j] = fixed(kbar_i[j], j)\n",
    "print(m_likelihood())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbar = np.zeros(N_p)\n",
    "fbar[common_indices] = np.log(np.exp(f_observed)-1)\n",
    "\n",
    "print('-------')\n",
    "print(np.sum(m_likelihood(δbar=-0.5))+δbar_prior(-0.5))\n",
    "print('------')\n",
    "old = 2\n",
    "print(np.sum(m_likelihood(δbar=old))+δbar_prior(old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('----- Metropolis Begins -----')\n",
    "clear_params = False\n",
    "if params is None or clear_params:\n",
    "    params = {'δ': list(), \n",
    "              'k': [list() for _ in range(num_genes)],\n",
    "              'σ': [list() for _ in range(num_genes)],\n",
    "              'w': [list() for _ in range(num_genes)],\n",
    "              'L': list(),\n",
    "              'V': list()\n",
    "             }\n",
    "T = 2000\n",
    "\n",
    "for iteration_number in range(T):\n",
    "    if iteration_number % 50 == 0:\n",
    "        print(f'{100*iteration_number/T:.2f}% complete', end='\\r')\n",
    "        print('k', np.exp(kbar_i))\n",
    "    if iteration_number % 500 == 0:\n",
    "        pass\n",
    "#         f_plot = np.exp(fbar_i)\n",
    "#         f_plot = [f_plot[i*num_disc+i] for i in range(N_m)]\n",
    "#         plt.figure(figsize=(4, 4))\n",
    "#         plt.plot(f_plot)\n",
    "#         plt.title(f'f at iteration {iteration_number}')\n",
    "#         plt.show()\n",
    "\n",
    "    # Compute likelihood for comparison\n",
    "    old_m_likelihood = m_likelihood()\n",
    "    \n",
    "    # Untransformed tf mRNA vectors F\n",
    "    for i in range(I):\n",
    "        # Gibbs step\n",
    "        z_i = tf.reshape(tfd.MultivariateNormalDiag(fbar_i, h_f).sample(), (1, -1))\n",
    "        # MH\n",
    "        m, K = fbar_prior_params()\n",
    "        invKsigmaK = tf.matmul(tf.linalg.inv(K+tf.linalg.diag(h_f)), K) # (C_i + hI)C_i\n",
    "        L = tf.linalg.cholesky(K-tf.matmul(K, invKsigmaK))\n",
    "        c_mu = tf.matmul(z_i, invKsigmaK)\n",
    "        fstar = tf.matmul(tf.random.normal((1, L.shape[0])), L) + c_mu\n",
    "        fstar = tf.reshape(fstar, (-1, ))\n",
    "#         print(fstar)\n",
    "        new_prob = np.sum(m_likelihood(fbar=fstar)) + f_likelihood(fstar)\n",
    "        old_prob = np.sum(old_m_likelihood) + f_likelihood(fbar_i)\n",
    "#         print(m_likelihood(fbar=fstar), m_likelihood(fbar=fbar_i))\n",
    "#         print(g(fstar), g(fbar_i))\n",
    "        if is_accepted(new_prob, old_prob):\n",
    "#             print('f accepted')\n",
    "            fbar_i = fstar\n",
    "\n",
    "\n",
    "    # Log of translation ODE degradation rates\n",
    "    for i in range(I):# TODO make for I > 1\n",
    "        # Proposal distribution\n",
    "        Q = tfd.Normal(δbar_i, h_δ)\n",
    "        δstar = Q.sample() # δstar is in log-space, i.e. δstar = δbar*\n",
    "        new_prob = np.sum(m_likelihood(δbar=δstar)) + δbar_prior(δstar)\n",
    "        old_prob = np.sum(old_m_likelihood) + δbar_prior(δbar_i)\n",
    "#         print()\n",
    "#         print(δstar, δbar_prior(δstar))\n",
    "#         print(new_prob, old_prob)\n",
    "        if is_accepted(new_prob, old_prob):\n",
    "            δbar_i = δstar\n",
    "            params['δ'].append(δstar)\n",
    "\n",
    "            \n",
    "    # Log of transcription ODE kinetic params\n",
    "    kstar = kbar_i.copy()\n",
    "    for j in range(num_genes):\n",
    "        Q = tfd.MultivariateNormalDiag(kbar_i[j], h_k)\n",
    "        sample = fixed(Q.sample().numpy(), j)\n",
    "#         print('sample', sample)\n",
    "        kstar[j] = sample\n",
    "        new_prob = m_likelihood(kbar=kstar)[j] + np.sum(kbar_prior(sample))\n",
    "        old_prob = old_m_likelihood[j] + np.sum(kbar_prior(kbar_i[j]))\n",
    "#         print(new_prob, old_prob, kbar_prior(kstar))\n",
    "        if is_accepted(new_prob, old_prob):\n",
    "            kbar_i[j] = kstar[j]\n",
    "            params['k'][j].append(kstar[j])\n",
    "        else:\n",
    "            kstar[j] = kbar_i[j]\n",
    "\n",
    "    \n",
    "    # Interaction weights and biases (note: should work for I > 1)\n",
    "    wstar = w_j.copy()\n",
    "    for j in range(num_genes):\n",
    "        Q = tfd.Normal(w_j[j], 0.1)#h_w[j])\n",
    "        sample = Q.sample()[0]\n",
    "        wstar[j] = sample\n",
    "        new_prob = m_likelihood(w=wstar)[j] + np.sum(w_j_prior(sample))\n",
    "        old_prob = old_m_likelihood[j] + np.sum(w_j_prior(w_j[j,:]))\n",
    "#         print('----')\n",
    "#         print(g(wstar))\n",
    "#         print(g(w_j[j][0]))\n",
    "        if is_accepted(new_prob, old_prob):\n",
    "            w_j[j] = sample\n",
    "            params['w'][j].append(sample)\n",
    "        else:\n",
    "            wstar[j] = w_j[j]\n",
    "\n",
    "    # Noise variances\n",
    "    for j in range(num_genes):\n",
    "        Q = lambda σ: tfd.TruncatedNormal(σ, h_σm, low=0, high=5)\n",
    "        sample = Q(σ2_m[j]).sample()\n",
    "        σ2_mstar = σ2_m.copy()\n",
    "        σ2_mstar[j] = sample\n",
    "        new_prob = m_likelihood(σ=σ2_mstar)[j] + σ2_m_prior(σ2_mstar[j]) + Q(σ2_mstar[j]).log_prob(σ2_m[j])\n",
    "        old_prob: m_likelihood(σ=σ2_m)[j] + σ2_m_prior(σ2_m[j]) + Q(σ2_m[j]).log_prob(σ2_mstar[j])\n",
    "        if is_accepted(new_prob, old_prob):\n",
    "            σ2_m[j] = σ2_mstar[j]\n",
    "            params['σ'][j].append(σ2_mstar[j])\n",
    "    \n",
    "    # Length scales and variances of GP kernels\n",
    "#     for i in range(I):\n",
    "#         Q_v = lambda v: tfd.TruncatedNormal(v, l2_i, low=0, high=100)\n",
    "#         Q_l = lambda l2: tfd.TruncatedNormal(l2, h_c, low=0, high=100)\n",
    "#         vstar = Q_v(v_i).sample()\n",
    "#         l2star = Q_l(l2_i).sample()\n",
    "# #         print(vstar, l2star, 'prior', fbar_prior(fbar_i, vstar, l2star))\n",
    "#         g = lambda v, l2, v_other, l2_other: fbar_prior(fbar_i, v, l2) + \\\n",
    "#             v_prior(v) + l2_prior(l2) + Q_v(v_other).log_prob(v) + Q_l(l2_other).log_prob(l2)\n",
    "# #         print(g(v_i, l2_i, vstar, l2star))\n",
    "#         if is_accepted(g(vstar, l2star, v_i, l2_i), g(v_i, l2_i, vstar, l2star)):\n",
    "# #             print(\"accepted\")\n",
    "#             v_i = vstar\n",
    "#             l2_i = l2star\n",
    "#             params['V'].append(vstar)\n",
    "#             params['L'].append(l2star)\n",
    "\n",
    "print('----- Finished -----')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decay\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, param in enumerate(['δ', 'L', 'V']):\n",
    "    ax = plt.subplot(331+i)\n",
    "    plt.plot(params[param])\n",
    "    ax.set_title(param)\n",
    "#'σ', 'w']):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot transcription ODE kinetic params\n",
    "plt.figure(figsize=(10, 14))\n",
    "plt.title('Transcription ODE kinetic parameters')\n",
    "labels = ['a', 'b', 'd', 's']\n",
    "for j in range(num_genes):\n",
    "    ax = plt.subplot(num_genes, 2, j+1)\n",
    "    k_param = np.array(params['k'][j])\n",
    "    print(k_param.shape)\n",
    "    \n",
    "    for k in range(4):\n",
    "        plt.plot(k_param[:, k], label=labels[k])\n",
    "    plt.legend()\n",
    "    ax.set_title(f'Gene {j}')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(10, 14))\n",
    "k_latest = np.exp(np.array([\n",
    "    np.mean(np.array(params['k'][j])[-10:], axis=0) for j in range(num_genes)]))\n",
    "print(k_latest)\n",
    "B = k_latest[:,1]\n",
    "D = k_latest[:,2]\n",
    "S = k_latest[:,3]\n",
    "print(B)\n",
    "B_barenco = np.array([2.6, 1.5, 0.5, 0.2, 1.35])# From Martino paper ... but don't know the scale\n",
    "B_barenco = B_barenco/np.mean(B_barenco)*np.mean(B)# do a rough rescaling so that the scales match.\n",
    "S_barenco = np.array([3, 0.8, 0.7, 1.8, 0.7])/1.8\n",
    "D_barenco = np.array([1.2, 1.6, 1.75, 3.2, 2.3])*0.8/3.2\n",
    "\n",
    "\n",
    "data = [B, S, D]\n",
    "barenco_data = [B_barenco, S_barenco, D_barenco]\n",
    "labels = ['Basal rates', 'Sensitivities', 'Decay rates']\n",
    "\n",
    "plotnum = 331\n",
    "for A, B, label in zip(data, barenco_data, labels):\n",
    "    plt.subplot(plotnum)\n",
    "    plotnum+=1\n",
    "    plt.bar(np.arange(5)-0.2, A, width=0.4)\n",
    "    plt.bar(np.arange(5)+0.2, B, width=0.4, color='blue', align='center')\n",
    "\n",
    "    plt.title(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot genes\n",
    "plt.figure(figsize=(10, 10))\n",
    "m_pred = predict_m(kbar_i, δbar_i, w_j, fbar_i)\n",
    "print(m_pred.shape)\n",
    "for j in range(num_genes):\n",
    "    plt.subplot(531+j)\n",
    "    plt.plot(m_pred[j, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('Noise variances')\n",
    "for i, j in enumerate(range(num_genes)):\n",
    "    ax = plt.subplot(num_genes, num_genes-2, i+1)\n",
    "    plt.plot(params['σ'][j]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_i = np.log(1+np.exp(fbar_i))\n",
    "plt.plot(f_i)\n",
    "plt.figure()\n",
    "plt.plot(f_i[common_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
