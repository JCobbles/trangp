{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from collections import namedtuple\n",
    "\n",
    "import gpflow\n",
    "from gpflow.utilities import print_summary, positive\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import math as tfm\n",
    "from tensorflow_probability import bijectors as tfb\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow_probability import mcmc\n",
    "\n",
    "from load_puma_data import load_barenco_puma\n",
    "import math\n",
    "import random\n",
    "\n",
    "PI = tf.constant(math.pi, dtype='float64')\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, genes, genes_se, Y, Y_var = load_barenco_puma()\n",
    "\n",
    "\n",
    "N_m = 7               # Number of observations\n",
    "def calc_N_p(N_p, num_disc=8):\n",
    "    '''A helper recursive function to ensure t is a subset of τ'''\n",
    "    if num_disc <= 0:\n",
    "        return N_p\n",
    "    return N_p -1 + calc_N_p(N_p, num_disc-1)\n",
    "num_disc = 10\n",
    "N_p = calc_N_p(N_m, num_disc)  # Number of time discretisations\n",
    "common_indices = np.array([i*num_disc+i for i in range(N_m)])\n",
    "t = np.arange(N_m)*2           # Observation times\n",
    "τ = np.linspace(0, 12, N_p, dtype='float64')    # Discretised observation times\n",
    "num_genes = 5\n",
    "I = 1 # Number of TFs\n",
    "\n",
    "m_observed = np.float64(Y[:-1])\n",
    "f_observed = np.float64(np.atleast_2d(Y[-1]))\n",
    "σ2 = np.float64(Y_var[:-1])\n",
    "σ2_f = np.float64(np.atleast_2d(Y_var[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis Hastings Custom MCMC Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
    "\n",
    "def get_rbf_dist(times, N):\n",
    "    t_1 = np.reshape(np.tile(times, N), [N, N]).T\n",
    "    t_2 = np.reshape(np.tile(times, N), [N, N])\n",
    "    return t_1-t_2\n",
    "\n",
    "def jitter_cholesky(A):\n",
    "    try:\n",
    "        jitter1 = tf.linalg.diag(1e-7 * np.ones(A.shape[0]))\n",
    "        return tf.linalg.cholesky(A + jitter1)\n",
    "    except:\n",
    "        jitter2 = tf.linalg.diag(1e-5 * np.ones(A.shape[0]))\n",
    "        return tf.linalg.cholesky(A + jitter2)\n",
    "\n",
    "info = np.finfo('float64')\n",
    "def exp(x):\n",
    "    '''Safe exp'''\n",
    "    with np.errstate(under='ignore', over='ignore'):\n",
    "        return np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='raise')\n",
    "\n",
    "class MetropolisHastings():\n",
    "    '''MH accept function'''\n",
    "    def is_accepted(self, new_log_prob, old_log_prob):\n",
    "        alpha = exp(new_log_prob - old_log_prob)\n",
    "        if tf.is_tensor(alpha):\n",
    "            alpha = alpha.numpy()\n",
    "        return not np.isnan(alpha) and random.random() < min(1, alpha)\n",
    "\n",
    "class TranscriptionLikelihood():\n",
    "    def predict_m(self, kbar, δbar, w, fbar, w_0):\n",
    "        # Take relevant parameters out of log-space\n",
    "        a_j, b_j, d_j, s_j = (np.exp(kbar[:, i]).reshape(-1, 1) for i in range(4))\n",
    "        δ = np.exp(δbar)\n",
    "        f_i = np.log(1+np.exp(fbar))\n",
    "    #     print('f_i', f_i)\n",
    "\n",
    "        # Calculate p_i vector\n",
    "        p_i = np.zeros(N_p) # TODO it seems the ODE translation model has params A, S see gpmtfComputeTFODE\n",
    "        Δ = τ[1]-τ[0]\n",
    "        sum_term = exp(δ*τ) * f_i\n",
    "        p_i[1:] = 0.5*Δ*np.cumsum(sum_term[:-1] + sum_term[1:]) # Trapezoid rule\n",
    "        p_i = exp(-δ*τ) * p_i\n",
    "    #     print('pi', p_i)\n",
    "\n",
    "        # Calculate m_pred\n",
    "        integrals = np.zeros((num_genes, N_p))\n",
    "        interactions = w[:, 0][:, None]*np.log(p_i+1e-50) + w_0    \n",
    "        G = 1/(1+np.exp(-interactions)) # TF Activation Function\n",
    "        sum_term = G * np.exp(d_j*τ)\n",
    "        integrals[:, 1:] = 0.5*Δ*np.cumsum(sum_term[:, :-1] + sum_term[:, 1:], axis=1) # Trapezoid rule\n",
    "        exp_dt = np.exp(-d_j*τ)\n",
    "        integrals = exp_dt * integrals\n",
    "        m_pred = b_j/d_j + (a_j-b_j/d_j)*exp_dt + s_j*integrals\n",
    "\n",
    "        return m_pred\n",
    "\n",
    "    def genes(self, params, δbar=None, \n",
    "                     fbar=None, \n",
    "                     kbar=None, \n",
    "                     w=None,\n",
    "                     σ2_m=None):\n",
    "        '''\n",
    "        Computes likelihood of the genes.\n",
    "        If any of the optional args are None, they are replaced by their current value in params.\n",
    "        '''\n",
    "        if δbar is None:\n",
    "            δbar = params.δbar.value\n",
    "        if fbar is None:\n",
    "            fbar = params.fbar.value\n",
    "        if kbar is None:\n",
    "            kbar = params.kbar.value\n",
    "        w = params.w.value if w is None else w\n",
    "        σ2_m = params.σ2_m.value if σ2_m is None else σ2_m\n",
    "\n",
    "        w_0 = 0 # TODO no hardcode this!\n",
    "        m_pred = self.predict_m(kbar, δbar, w, fbar, w_0)\n",
    "\n",
    "        log_lik = np.zeros(num_genes)\n",
    "        sq_diff = np.square(m_observed - m_pred[:, common_indices])\n",
    "        variance = σ2_m.reshape(-1, 1) + σ2 # add PUMA variance\n",
    "        log_lik = -0.5*np.log(2*np.pi*(variance)) - 0.5*sq_diff/variance\n",
    "        log_lik = np.sum(log_lik, axis=1)\n",
    "\n",
    "        return log_lik\n",
    "\n",
    "    def tfs(self, fbar, i=0): \n",
    "        '''\n",
    "        Computes log-likelihood of the transcription factors.\n",
    "        TODO this should be for the i-th TF\n",
    "        '''\n",
    "        f_pred = np.log(1+np.exp(fbar))\n",
    "        f_pred = np.float64(np.atleast_2d(f_pred[common_indices]))\n",
    "        sq_diff = np.square(f_observed[i] - f_pred[i])\n",
    "#         prob = tfd.Normal(f_observed[i], σ2_f[i]).log_prob(f_i[i])\n",
    "        log_lik = -0.5*sum(np.log(2*np.pi*σ2_f[i])) - 0.5*sum(sq_diff/σ2_f[i])\n",
    "        return log_lik\n",
    "\n",
    "class Parameter():\n",
    "    def __init__(self, prior, initial_value, proposal_dist=None, name=None, constraint=None):\n",
    "        self.name = name\n",
    "        self.prior = prior\n",
    "        self.proposal_dist = proposal_dist\n",
    "        if constraint is None:\n",
    "            self.constrained = lambda x:x\n",
    "        else:\n",
    "            self.constrained = constraint\n",
    "        self.value = initial_value\n",
    "\n",
    "    def set_value(self, value):\n",
    "        this.value = value\n",
    "    def constrain(self, *args):\n",
    "        return self.constrained(*args)\n",
    "    \n",
    "    def propose(self, *args):\n",
    "        assert self.proposal_dist is not None, 'proposal_dist must not be None if you use propose()'\n",
    "        return self.proposal_dist(*args).sample().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f64 = np.float64\n",
    "class TranscriptionMCMC(MetropolisHastings):\n",
    "    def __init__(self):\n",
    "        self.likelihood = TranscriptionLikelihood()\n",
    "        self.clear_samples()\n",
    "        # Adaptable variances\n",
    "        a = tf.constant(-0.5, dtype='float64')\n",
    "        b2 = tf.constant(2., dtype='float64')\n",
    "        self.h_δ = 0.15\n",
    "        h_c = 0.1\n",
    "        self.h_f = 0.4*tf.ones(N_p, dtype='float64')\n",
    "        self.h_k = 0.15*tf.ones(4, dtype='float64')\n",
    "        h_w = tf.ones(num_genes, dtype='float64')\n",
    "        h_σm = tf.constant(0.1, dtype='float64')\n",
    "\n",
    "        # Interaction weights\n",
    "        w_j0 = 0   \n",
    "        w = Parameter(\n",
    "            tfd.Normal(0, 2), \n",
    "            0.1*np.ones((num_genes, I)),\n",
    "            proposal_dist=lambda mu:tfd.Normal(mu, 0.1)) #h_w[j]) w_j) # At the moment this is the same as w_j0 (see pg.8)\n",
    "        # Latent function\n",
    "        fbar = Parameter(\n",
    "            self.fbar_prior, \n",
    "            0.5*np.ones(N_p))\n",
    "        # GP hyperparameters\n",
    "        V = Parameter(tfd.InverseGamma(f64(0.1), f64(0.1)), f64(1), \n",
    "                      proposal_dist=lambda v: tfd.TruncatedNormal(v, h_c, low=0, high=100)) #v_i Fix to 1 if translation model is not used (pg.8)\n",
    "        L = Parameter(tfd.InverseGamma(f64(0.1), f64(0.1)), f64(0.1),\n",
    "                      proposal_dist=lambda l2: tfd.TruncatedNormal(l2, h_c, low=0, high=100)) #l2_i\n",
    "        # Translation kinetic parameters\n",
    "        δbar = Parameter(tfd.Normal(a, b2), f64(-0.3), proposal_dist=lambda mu:tfd.Normal(mu, self.h_δ))\n",
    "        # White noise for genes\n",
    "        σ2_m = Parameter(tfd.InverseGamma(f64(0.01), f64(0.01)), 1e-2*np.ones(num_genes),\n",
    "                         proposal_dist=lambda mu: tfd.TruncatedNormal(mu, h_σm, low=0, high=5))\n",
    "        # Transcription kinetic parameters\n",
    "        def constrain_kbar(kbar, gene):\n",
    "            '''Constrains a given row in kbar'''\n",
    "            if gene == 3:\n",
    "                kbar[2] = np.log(0.8)\n",
    "                kbar[3] = np.log(1.0)\n",
    "            kbar[kbar < -10] = -10\n",
    "            kbar[kbar > 2] = 2\n",
    "            return kbar\n",
    "        kbar_initial = -0.1*np.float64(np.c_[\n",
    "            np.ones(num_genes), # a_j\n",
    "            np.ones(num_genes), # b_j\n",
    "            np.ones(num_genes), # d_j\n",
    "            np.ones(num_genes)  # s_j\n",
    "        ])\n",
    "        for j, k in enumerate(kbar_initial):\n",
    "            kbar_initial[j] = constrain_kbar(k, j)\n",
    "        kbar = Parameter(\n",
    "            tfd.Normal(a, b2), \n",
    "            kbar_initial,\n",
    "            proposal_dist=lambda mu: tfd.MultivariateNormalDiag(mu, self.h_k),\n",
    "            constraint=constrain_kbar)\n",
    "        params = namedtuple('parameters', ['fbar','δbar','kbar','σ2_m','w','L','V'])\n",
    "        self.params = params(fbar, δbar, kbar, σ2_m, w, L, V)\n",
    "        \n",
    "    def fbar_prior_params(self, v, l2):\n",
    "        t_dist = get_rbf_dist(τ, N_p)\n",
    "    #     print('vl2', v, l2)\n",
    "        jitter = tf.linalg.diag(1e-5 * np.ones(N_p))\n",
    "        try:\n",
    "            K = v * exp(-np.square(t_dist)/(2*l2)) + jitter\n",
    "        except:\n",
    "#             print('HELP! sq', -np.square(t_dist)/(2*l2))\n",
    "#             raise 'Error!'\n",
    "            K = np.eye(N_p)\n",
    "\n",
    "    #     print(K)\n",
    "        m = np.zeros(N_p)\n",
    "        return m, K\n",
    "\n",
    "    def fbar_prior(self, fbar, v, l2):\n",
    "        m, K = self.fbar_prior_params(v, l2)\n",
    "\n",
    "        try:\n",
    "            return tfd.MultivariateNormalFullCovariance(m, K).log_prob(fbar)\n",
    "        except:\n",
    "            jitter = tf.linalg.diag(1e-4 * np.ones(N_p))\n",
    "            try:\n",
    "                return np.float64(tfd.MultivariateNormalFullCovariance(m, K+jitter).log_prob(fbar))\n",
    "            except:\n",
    "                return 0\n",
    "\n",
    "    def clear_samples(self):\n",
    "        self.samples = {\n",
    "            'δbar': list(), \n",
    "            'kbar': [list() for _ in range(num_genes)],\n",
    "            'σ2_m': [list() for _ in range(num_genes)],\n",
    "            'w': [list() for _ in range(num_genes)],\n",
    "            'L': list(),\n",
    "            'V': list(),\n",
    "            'fbar': list(),\n",
    "            'acc_rates': list()\n",
    "        }\n",
    "        \n",
    "    def adapt(self):\n",
    "        T = 5\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i, h_δ_test in enumerate(np.linspace(0.1, 0.25, T)):\n",
    "            self.clear_samples()\n",
    "            self.h_δ = h_δ_test\n",
    "            plt.subplot(T, 3, i+1)\n",
    "            self.sample(T=300, store_every=1, burn_in=0, report_every=200) # sample, do not report\n",
    "            plt.acorr(self.samples['δbar'], maxlags=50)\n",
    "            plt.tight_layout()\n",
    "            plt.xlim(-1, 50)\n",
    "            plt.title(f'h_δ = {h_δ_test:3f}')\n",
    "            print(self.acceptance_rates)\n",
    "        \n",
    "        # Selecting...\n",
    "        self.h_δ = 0.30\n",
    "        self.clear_samples()\n",
    "        self.sample(T=1000, store_every=1, burn_in=0)\n",
    "#         plt.plot(self.samples['acceptance_rates']['δ'])\n",
    "    \n",
    "    def sample(self, T=20000, store_every=10, burn_in=1000, report_every=100):\n",
    "        print('----- Metropolis Begins -----')\n",
    "        self.acceptance_rates = { # Reset acceptance rates\n",
    "            'f': 0.,\n",
    "            'δ': 0.,\n",
    "            'k': 0.,\n",
    "            'σ': 0.,\n",
    "            'w': 0.,\n",
    "            'L': 0.,\n",
    "            'V': 0.\n",
    "        }\n",
    "\n",
    "        for iteration_number in range(T):\n",
    "            if iteration_number % report_every == 0:\n",
    "                print(f'{100*iteration_number/T:.2f}% complete', end='\\r')\n",
    "\n",
    "            self.iterate()\n",
    "    \n",
    "            if iteration_number >= burn_in and iteration_number % store_every == 0:\n",
    "                for j in range(num_genes):\n",
    "                    self.samples['σ2_m'][j].append(self.params.σ2_m.value[j].copy())\n",
    "                    self.samples['w'][j].append(self.params.w.value[j].copy())\n",
    "                    self.samples['kbar'][j].append(self.params.kbar.value[j].copy())\n",
    "\n",
    "                self.samples['V'].append(self.params.V.value)\n",
    "                self.samples['L'].append(self.params.L.value)\n",
    "                self.samples['δbar'].append(self.params.δbar.value)\n",
    "                self.samples['fbar'].append(self.params.fbar.value)\n",
    "                self.samples['acc_rates'].append(list(self.acceptance_rates.values()))\n",
    "                \n",
    "        for key in self.acceptance_rates:\n",
    "            self.acceptance_rates[key] /= T\n",
    "        print('----- Finished -----')\n",
    "\n",
    "    def iterate(self):\n",
    "        params = self.params\n",
    "        # Compute likelihood for comparison\n",
    "        old_m_likelihood = self.likelihood.genes(params)\n",
    "        \n",
    "        # Untransformed tf mRNA vectors F\n",
    "        fbar = params.fbar.value\n",
    "        for i in range(I):\n",
    "            # Gibbs step\n",
    "            z_i = tf.reshape(tfd.MultivariateNormalDiag(fbar, self.h_f).sample(), (1, -1))\n",
    "            # MH\n",
    "            m, K = self.fbar_prior_params(params.V.value, params.L.value)\n",
    "            invKsigmaK = tf.matmul(tf.linalg.inv(K+tf.linalg.diag(self.h_f)), K) # (C_i + hI)C_i\n",
    "            L = jitter_cholesky(K-tf.matmul(K, invKsigmaK))\n",
    "            c_mu = tf.matmul(z_i, invKsigmaK)\n",
    "            fstar = tf.matmul(tf.random.normal((1, L.shape[0]), dtype='float64'), L) + c_mu\n",
    "            fstar = tf.reshape(fstar, (-1, ))\n",
    "            \n",
    "            new_prob = np.sum(self.likelihood.genes(params, fbar=fstar)) + self.likelihood.tfs(fstar)\n",
    "            old_prob = np.sum(old_m_likelihood) + self.likelihood.tfs(fbar)\n",
    "            if self.is_accepted(new_prob, old_prob):\n",
    "                params.fbar.value = fstar\n",
    "                self.acceptance_rates['f'] += 1/I\n",
    "\n",
    "\n",
    "        # Log of translation ODE degradation rates\n",
    "        δbar = params.δbar.value\n",
    "        for i in range(I):# TODO make for I > 1\n",
    "            # Proposal distribution\n",
    "            δstar = params.δbar.propose(δbar) # δstar is in log-space, i.e. δstar = δbar*\n",
    "            new_prob = np.sum(self.likelihood.genes(params, δbar=δstar)) + params.δbar.prior.log_prob(δstar)\n",
    "            old_prob = np.sum(old_m_likelihood) + params.δbar.prior.log_prob(δbar)\n",
    "#             print(δstar, params.δbar.prior.log_prob(δstar))\n",
    "#             print(new_prob, old_prob)\n",
    "            if self.is_accepted(new_prob, old_prob):\n",
    "                params.δbar.value = δstar\n",
    "                self.acceptance_rates['δ'] += 1/I\n",
    "\n",
    "        # Log of transcription ODE kinetic params\n",
    "        kbar = params.kbar.value\n",
    "        kstar = kbar.copy()\n",
    "        for j in range(num_genes):\n",
    "            sample = params.kbar.propose(kstar[j])\n",
    "            sample = params.kbar.constrain(sample, j)\n",
    "\n",
    "            kstar[j] = sample\n",
    "            new_prob = self.likelihood.genes(params, kbar=kstar)[j] + sum(params.kbar.prior.log_prob(sample))\n",
    "            old_prob = old_m_likelihood[j] + sum(params.kbar.prior.log_prob(kbar[j]))\n",
    "            if self.is_accepted(new_prob, old_prob):\n",
    "                test = params.kbar.value\n",
    "                test[j]=sample\n",
    "                params.kbar.value = test\n",
    "                self.acceptance_rates['k'] += 1/num_genes\n",
    "            else:\n",
    "                kstar[j] = params.kbar.value[j]\n",
    "\n",
    "\n",
    "        # Interaction weights and biases (note: should work for I > 1)\n",
    "        w = params.w.value\n",
    "        wstar = w.copy()\n",
    "        for j in range(num_genes):\n",
    "            sample = params.w.propose(wstar[j])\n",
    "            wstar[j] = sample\n",
    "            new_prob = self.likelihood.genes(params, w=wstar)[j] + sum(params.w.prior.log_prob(sample))\n",
    "            old_prob = old_m_likelihood[j] + sum(params.w.prior.log_prob(w[j,:]))\n",
    "            if self.is_accepted(new_prob, old_prob):\n",
    "                params.w.value[j] = sample\n",
    "                self.acceptance_rates['w'] += 1/num_genes\n",
    "            else:\n",
    "                wstar[j] = params.w.value[j]\n",
    "\n",
    "        # Noise variances\n",
    "        σ2_m = params.σ2_m.value\n",
    "        σ2_mstar = σ2_m.copy()\n",
    "        for j in range(num_genes):\n",
    "            sample = params.σ2_m.propose(σ2_m[j])\n",
    "            σ2_mstar[j] = sample\n",
    "            old_q = params.σ2_m.proposal_dist(σ2_mstar[j]).log_prob(σ2_m[j])\n",
    "            new_prob = self.likelihood.genes(params, σ2_m=σ2_mstar)[j] +params.σ2_m.prior.log_prob(σ2_mstar[j])\n",
    "            \n",
    "            new_q = params.σ2_m.proposal_dist(σ2_m[j]).log_prob(σ2_mstar[j])\n",
    "            old_prob = self.likelihood.genes(params, σ2_m=σ2_m)[j] + params.σ2_m.prior.log_prob(σ2_m[j])\n",
    "                \n",
    "            if self.is_accepted(new_prob + old_q, old_prob + new_q):\n",
    "                params.σ2_m.value[j] = sample\n",
    "                self.acceptance_rates['σ'] += 1/num_genes\n",
    "            else:\n",
    "                σ2_mstar[j] = σ2_m[j]\n",
    "\n",
    "        # Length scales and variances of GP kernels\n",
    "        l2 = params.L.value\n",
    "        v = params.V.value\n",
    "        for i in range(I):\n",
    "            # Proposal distributions\n",
    "            Q_v = params.V.proposal_dist\n",
    "            Q_l = params.L.proposal_dist\n",
    "            vstar = params.V.propose(v)\n",
    "            l2star = params.L.propose(l2)\n",
    "#             print(vstar, l2star)# 'prior', fbar_prior(fbar_i, vstar, l2star))\n",
    "            # Acceptance probabilities\n",
    "            old_q = Q_v(vstar).log_prob(v) + Q_l(l2star).log_prob(l2) # Q(old|new)\n",
    "            new_prob = params.fbar.prior(params.fbar.value, vstar, l2star) + params.V.prior.log_prob(vstar) + params.L.prior.log_prob(l2star)\n",
    "\n",
    "            new_q = Q_v(v).log_prob(vstar) + Q_l(l2).log_prob(l2star) # Q(new|old)\n",
    "            old_prob = params.fbar.prior(params.fbar.value, v, l2) + params.V.prior.log_prob(v) + params.L.prior.log_prob(l2)\n",
    "\n",
    "            accepted = self.is_accepted(new_prob + old_q, old_prob + new_q)\n",
    "            if accepted:\n",
    "#                 print(\"accepted\")\n",
    "                params.V.value = vstar\n",
    "                params.L.value = l2star\n",
    "                self.acceptance_rates['V'] += 1/I\n",
    "                self.acceptance_rates['L'] += 1/I\n",
    "\n",
    "    def predict_m(self):\n",
    "        return self.likelihood.predict_m(self.params.kbar.value, \n",
    "                                         self.params.δbar.value, \n",
    "                                         self.params.w.value, \n",
    "                                         self.params.fbar.value, 0)\n",
    "\n",
    "transcription_model = TranscriptionMCMC()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin MCMC Adaptive phase\n",
    "transcription_model.adapt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin MCMC\n",
    "T = 1000\n",
    "store_every = 20\n",
    "burn_in = 100\n",
    "report_every = 50\n",
    "\n",
    "transcription_model.sample(T, store_every, burn_in, report_every)\n",
    "\n",
    "print(transcription_model.acceptance_rates)\n",
    "\n",
    "samples = transcription_model.samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step size is standard dev, too small means it takes long time to reach high density areas. too long means we reject many of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = transcription_model.samples\n",
    "\n",
    "plt.figure(figsize=(10,14))\n",
    "\n",
    "parameter_names = transcription_model.acceptance_rates.keys()\n",
    "acc_rates = np.array(samples['acc_rates'])\n",
    "print(T/(acc_rates.shape[0]+1))\n",
    "for i, name in enumerate(parameter_names):\n",
    "    plt.subplot(len(parameter_names), 3, i+1)\n",
    "    deltas = acc_rates[:, i]/np.arange(1, T-burn_in, store_every)\n",
    "    plt.plot(deltas)\n",
    "    plt.title(name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decay\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, param in enumerate(['δbar', 'L', 'V']):\n",
    "    ax = plt.subplot(331+i)\n",
    "    plt.plot(samples[param])\n",
    "    ax.set_title(param)\n",
    "#'σ', 'w']):\n",
    "\n",
    "plt.figure()\n",
    "for j in range(num_genes):\n",
    "    plt.plot(samples['w'][j])\n",
    "    \n",
    "plt.title('Interaction weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot transcription ODE kinetic params\n",
    "plt.figure(figsize=(10, 14))\n",
    "plt.title('Transcription ODE kinetic parameters')\n",
    "labels = ['a', 'b', 'd', 's']\n",
    "for j in range(num_genes):\n",
    "    ax = plt.subplot(num_genes, 2, j+1)\n",
    "    k_param = np.array(samples['kbar'][j])\n",
    "#     print(k_param)\n",
    "    \n",
    "    for k in range(4):\n",
    "        plt.plot(k_param[:, k], label=labels[k])\n",
    "    plt.legend()\n",
    "    ax.set_title(f'Gene {j}')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(14, 14))\n",
    "k_latest = np.exp(np.array([\n",
    "    np.mean(np.array(samples['kbar'][j])[-10:], axis=0) for j in range(num_genes)]))\n",
    "print(k_latest)\n",
    "B = k_latest[:,1]\n",
    "D = k_latest[:,2]\n",
    "S = k_latest[:,3]\n",
    "print(B)\n",
    "B_barenco = np.array([2.6, 1.5, 0.5, 0.2, 1.35])# From Martino paper ... but don't know the scale\n",
    "B_barenco = B_barenco/np.mean(B_barenco)*np.mean(B)# do a rough rescaling so that the scales match.\n",
    "S_barenco = np.array([3, 0.8, 0.7, 1.8, 0.7])/1.8\n",
    "D_barenco = np.array([1.2, 1.6, 1.75, 3.2, 2.3])*0.8/3.2\n",
    "\n",
    "\n",
    "data = [B, S, D]\n",
    "barenco_data = [B_barenco, S_barenco, D_barenco]\n",
    "labels = ['Basal rates', 'Sensitivities', 'Decay rates']\n",
    "\n",
    "plotnum = 331\n",
    "for A, B, label in zip(data, barenco_data, labels):\n",
    "    plt.subplot(plotnum)\n",
    "    plotnum+=1\n",
    "    plt.bar(np.arange(5)-0.2, A, width=0.4, tick_label=df.index[:-1])\n",
    "    plt.bar(np.arange(5)+0.2, B, width=0.4, color='blue', align='center')\n",
    "\n",
    "    plt.title(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot genes\n",
    "plt.figure(figsize=(10, 10))\n",
    "m_pred = transcription_model.predict_m()\n",
    "print(m_pred.shape)\n",
    "for j in range(num_genes):\n",
    "    plt.subplot(531+j)\n",
    "    plt.plot(m_pred[j, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.title('Noise variances')\n",
    "for i, j in enumerate(range(num_genes)):\n",
    "    ax = plt.subplot(num_genes, num_genes-2, i+1)\n",
    "    plt.plot(samples['σ2_m'][j]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f():\n",
    "    f_i = np.log(1+np.exp(transcription_model.params.fbar.value))\n",
    "    plt.plot(f_i)\n",
    "    plt.figure()\n",
    "    f = f_i[common_indices]\n",
    "    f[0] = 0\n",
    "    scale_pred = np.sqrt(np.var(f));\n",
    "    barencof = np.array([[0.0, 200.52011, 355.5216125, 205.7574913, 135.0911372, 145.1080997, 130.7046969],\n",
    "                         [0.0, 184.0994134, 308.47592, 232.1775328, 153.6595161, 85.7272235, 168.0910562],\n",
    "                         [0.0, 230.2262511, 337.5994811, 276.941654, 164.5044287, 127.8653452, 173.6112139]])\n",
    "\n",
    "    barencof = barencof[0]/(np.sqrt(np.var(barencof[0])))*scale_pred;\n",
    "    measured_p53 = df[df.index.isin(['211300_s_at', '201746_at'])]\n",
    "    print(measured_p53)\n",
    "    measured_p53 = measured_p53.mean(0)\n",
    "    measured_p53 = measured_p53*scale_pred\n",
    "    lb = len(barencof)\n",
    "    print(lb)\n",
    "    plt.plot(np.arange(lb), f)\n",
    "    plt.scatter(np.arange(lb), barencof, marker='x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription_model.sample(T=1)\n",
    "plot_f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples['σ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fmean = (np.mean(samples['fbar'][-60::10], axis=0))\n",
    "plt.plot(fmean[common_indices])\n",
    "\n",
    "plt.figure()\n",
    "f = np.array(samples['fbar'])\n",
    "for i in common_indices:\n",
    "    plt.plot(f[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
