{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import gpflow\n",
    "from gpflow.utilities import print_summary, positive\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import math as tfm\n",
    "from tensorflow_probability import bijectors as tfb\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow_probability import mcmc\n",
    "\n",
    "from load_puma_data import load_barenco_puma\n",
    "import math\n",
    "import random\n",
    "\n",
    "PI = tf.constant(math.pi, dtype='float64')\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, genes, genes_se, Y, Y_var = load_barenco_puma()\n",
    "\n",
    "\n",
    "N_m = 7               # Number of observations\n",
    "def calc_N_p(N_p, num_disc=8):\n",
    "    '''A helper recursive function to ensure t is a subset of τ'''\n",
    "    if num_disc <= 0:\n",
    "        return N_p\n",
    "    return N_p -1 + calc_N_p(N_p, num_disc-1)\n",
    "num_disc = 10\n",
    "N_p = calc_N_p(N_m, num_disc)  # Number of time discretisations\n",
    "t = np.arange(N_m)*2           # Observation times\n",
    "τ = np.linspace(0, 12, N_p)    # Discretised observation times\n",
    "num_genes = 5\n",
    "I = 1 # Number of TFs\n",
    "\n",
    "m = np.float32(Y[:-1])\n",
    "f = np.float32(np.atleast_2d(Y[-1]))\n",
    "σ2 = np.float32(Y_var[:-1])\n",
    "σ2_f = np.float32(np.atleast_2d(Y_var[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis Hastings Custom MCMC Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "w_j0 = 1    # Interaction bias (TODO)\n",
    "fbar_i = np.ones(N_p, dtype='float32')\n",
    "v_i = 1 # Fix this to 1 if translation model is not used (pg.8)\n",
    "l2_i = 0.05\n",
    "δbar_i = np.float32(1)\n",
    "h_δ = 1\n",
    "h_f = tf.ones(N_p, dtype='float32')\n",
    "h_k = tf.ones(4, dtype='float32')\n",
    "h_w = tf.ones(num_genes, dtype='float32')\n",
    "a = tf.constant(-0.5, dtype='float32')\n",
    "b2 = tf.constant(2., dtype='float32')\n",
    "kbar_i = np.float32(np.c_[np.ones(num_genes), # a_j\n",
    "                          np.ones(num_genes), # b_j\n",
    "                          np.ones(num_genes), # d_j\n",
    "                          np.ones(num_genes)])# s_j\n",
    "w_j = 0.5*np.ones((num_genes, I))\n",
    "σm2 = np.ones(num_genes, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.30f}\".format(x)})\n",
    "\n",
    "# Priors\n",
    "def w_j_prior(w_j): # At the moment this is the same as w_j0 (see pg.8)\n",
    "    return np.float64(tfd.Normal(0, 2).prob(w_j0))\n",
    "def w_j0_prior(w_j0):\n",
    "    return tfd.Normal(0, 2).prob(w_j0)\n",
    "    \n",
    "def kbar_prior(kbar):\n",
    "    return np.prod(tfd.Normal(a, b2).prob(kbar))\n",
    "\n",
    "def fbar_prior_params():\n",
    "    t_1 = np.reshape(np.tile(τ, N_p), [N_p, N_p]).T\n",
    "    t_2 = np.reshape(np.tile(τ, N_p), [N_p, N_p])\n",
    "    t_dist = t_1-t_2\n",
    "    \n",
    "    K = v_i * np.exp(-np.square(t_dist)/(2*l2_i))\n",
    "    m = np.zeros(N_p)\n",
    "    return m, K\n",
    "\n",
    "def fbar_prior(fbar):\n",
    "    m, K = fbar_prior_params()\n",
    "    m = tf.cast(m, 'float32')#tf.zeros(N_p)\n",
    "    K = tf.cast(K, 'float32')#tf.linalg.diag(tf.ones(N_p))\n",
    "#     print(m)\n",
    "#     print(K)\n",
    "#     print('tfp', tfd.MultivariateNormalFullCovariance(m, K).prob(tf.ones(N_p)))\n",
    "    return np.float64(tfd.MultivariateNormalFullCovariance(m, K).prob(fbar))\n",
    "fbar_prior(fbar_i)\n",
    "\n",
    "\n",
    "def δbar_prior(δ):\n",
    "    return np.float64(tfd.Normal(a, b2).prob(δ))\n",
    "\n",
    "# Likelihood\n",
    "def G(n, k, p_i):\n",
    "    # TODO add binary vector x_j for prior network knowledge (pg.3)\n",
    "    numerator = np.exp(-d*(t[n]-τ[k]))\n",
    "    denominator = (1+np.exp(-w_j0-sum([w[:,i]*np.log(p_i[k]) for i in range(I)])))\n",
    "    return numerator/denominator\n",
    "\n",
    "    \n",
    "def m_likelihood(δbar, fbar, kbar, for_gene_only=False):        \n",
    "    # Take relevant parameters out of log-space\n",
    "    δ = np.exp(δbar)\n",
    "    f_i = np.exp(fbar)\n",
    "    a_j, b_j, d_j, s_j = (np.exp(kbar_i[:, i]) for i in range(4)) \n",
    "#     print('exped', δ)\n",
    "    # Define p_i vector\n",
    "    p_i = np.zeros(N_p)\n",
    "    for n in range(N_p):\n",
    "        N_pn = n#n*10+n\n",
    "        p_i[n] = np.trapz([f_i[k] * np.exp(-δ*(τ[n]-τ[k])) for k in range(N_pn)])\n",
    "#     print('pi', p_i)\n",
    "    \n",
    "    # Calculate m_pred\n",
    "    m_pred = np.zeros((num_genes, N_m), dtype='float32')\n",
    "    for n in range(N_m):\n",
    "        N_pn = n*10+n\n",
    "        ys =  np.array([G(n, k, p_i) for k in range(N_pn)])\n",
    "        if ys.shape[0] == 0:\n",
    "            ys = np.zeros((0, num_genes))\n",
    "        integrals = np.array([np.trapz(ys[:, i]) for i in range(num_genes)])\n",
    "#         print('integrals', integrals)\n",
    "        m_pred[:, n] = b_j/d_j + (a_j-b_j/d_j) * np.exp(-d_j*t[n]) + s_j*integrals\n",
    "\n",
    "#     print(m_pred, m)\n",
    "    lik = 1    \n",
    "    if for_gene_only is False:\n",
    "        for j in range(num_genes):\n",
    "            prob = tfd.Normal(m[j], σ2[j]+σm2[j]).prob(m_pred[j])\n",
    "            lik *= tf.reduce_prod(prob)\n",
    "    else:\n",
    "        j = for_gene_only\n",
    "        prob = tfd.Normal(m[j], σ2[j]+σm2[j]).prob(m_pred[j])\n",
    "        lik *= tf.reduce_prod(prob)\n",
    "    return lik\n",
    "\n",
    "def f_likelihood(fbar, i=0): \n",
    "    '''TODO this should be for the i-th TF'''\n",
    "    f_i = np.exp(fbar)\n",
    "    f_i = np.float32(np.atleast_2d([f_i[i*num_disc+i] for i in range(N_m)]))\n",
    "#     print(f_i[i], f[i])\n",
    "    prob = tfd.Normal(f[i], σ2_f[i]).prob(f_i[i])\n",
    "#     print('prob', prob)\n",
    "    lik = tf.reduce_prod(prob)\n",
    "    return lik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Metropolis Begins -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jacob\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "print('----- Metropolis Begins -----')\n",
    "\n",
    "params = {'δ': list(), \n",
    "          'k': [list() for _ in range(num_genes)], \n",
    "          'w': [list() for _ in range(num_genes)]\n",
    "         }\n",
    "T = 100\n",
    "\n",
    "\n",
    "h_f =0.4*tf.ones(N_p, dtype='float32')\n",
    "\n",
    "# print(likelihood(δbar_i))\n",
    "for iteration_number in range(T):\n",
    "    if iteration_number % 10:\n",
    "        print(f'{100*iteration_number/T:.2f}% complete)\n",
    "    # Untransformed tf mRNA vectors F\n",
    "    for i in range(I):\n",
    "        # Gibbs step\n",
    "        z_i = tfd.MultivariateNormalDiag(fbar_i, h_f).sample()\n",
    "        # MH\n",
    "        m, K = fbar_prior_params()\n",
    "        m = tf.cast(m, 'float32')#tf.zeros(N_p)\n",
    "        K = tf.cast(K, 'float32')#tf.linalg.diag(tf.ones(N_p))\n",
    "\n",
    "        fstar = tfd.MultivariateNormalFullCovariance(m, K).sample()\n",
    "        fstar = tfd.MultivariateNormalDiag(fstar, h_f).sample()\n",
    "        g = lambda fbar: m_likelihood(δbar_i, fbar, kbar_i) * f_likelihood(fbar)\n",
    "        acceptance = g(fstar)/g(fbar_i)\n",
    "        if random.random() < min(1, acceptance):\n",
    "            fbar_i = fstar\n",
    "\n",
    "    # Log of translation ODE degradation rates\n",
    "    for i in range(I):\n",
    "        # Proposal distribution\n",
    "        Q = tfd.Normal(δbar_i, h_δ)\n",
    "        δstar = Q.sample() # δstar is in log-space, i.e. δstar = δbar*\n",
    "        g = lambda δbar: m_likelihood(δbar, fbar_i, kbar_i) * δbar_prior(δbar)\n",
    "        acceptance = min(1, g(δstar)/g(δbar_i))\n",
    "        if random.random() < acceptance:\n",
    "            δbar_i = δstar\n",
    "            params['δ'].append(δstar)\n",
    "            \n",
    "    # Log of transcription ODE kinetic params\n",
    "    for j in range(num_genes):\n",
    "        Q = tfd.MultivariateNormalDiag(kbar_i[j], h_k)\n",
    "        kstar = Q.sample()\n",
    "        g = lambda kbar: m_likelihood(δbar_i, fbar_i, kbar, for_gene_only=j) * kbar_prior(kbar)\n",
    "        acceptance = min(1, g(kstar)/g(kbar_i[j]))\n",
    "        if random.random() < acceptance:\n",
    "            kbar_i[j] = kstar\n",
    "            params['k'][j].append(kstar)\n",
    "\n",
    "    # Interaction weights and biases\n",
    "    for j in range(num_genes):\n",
    "        Q = tfd.Normal(w_j[j], 0.1)#h_w[j])\n",
    "        wstar = Q.sample()[0]\n",
    "        g = lambda w: m_likelihood(δbar_i, fbar_i, kbar_i, for_gene_only=j) * w_j_prior(w)\n",
    "#         print('----')\n",
    "#         print(g(wstar))\n",
    "#         print(g(w_j[j][0]))\n",
    "        acceptance = min(1, g(wstar)/g(w_j[j][0]))\n",
    "#         print('accept', acceptance)\n",
    "        if random.random() < acceptance:\n",
    "            w_j[j] = wstar\n",
    "            params['w'][j].append(wstar)\n",
    "\n",
    "    # Noise variances\n",
    "    \n",
    "    # Length scales and variances of GP kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
