{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from reggae.data_loaders import load_covid, DataHolder, scaled_barenco_data\n",
    "from reggae.mcmc import create_chains, MetropolisHastings, Parameter\n",
    "from reggae.utilities import discretise, logit, LogisticNormal\n",
    "from reggae.plot import plotters\n",
    "from reggae.models import TranscriptionLikelihood, Options, TranscriptionMixedSampler\n",
    "from reggae.models.results import GenericResults\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import math as tfm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz\n",
    "from ipywidgets import IntProgress\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "f64 = np.float64\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.4f}\".format(x)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As reported by https://jvi.asm.org/content/84/17/8369:\n",
    "tfs: IRF1, IRF7, STAT1, and STAT2\n",
    "gns: OAS1, RIG-I, Mx-1, ISG15, and ISG20, CXCL10 \n",
    "RIG-I is ENSMPUG00000004319\n",
    "\n",
    "GO:0035457, GO:0035458, GO:0035455, GO:0035456, GO:0034340, and HALLMARK_INTERFERON_ALPHA_RESPONSE\n",
    "subset of genes involved in the recruitment and activation of the adaptive immune response including: IL6, CXCL11, IFNG, IL7, CXCL9, and CXCL10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m_observed, f_observed, t = load_covid()\n",
    "\n",
    "m_df, m_observed = m_observed \n",
    "f_df, f_observed = f_observed\n",
    "# Shape of m_observed = (replicates, genes, times)\n",
    "m_observed = m_observed\n",
    "f_observed = f_observed\n",
    "\n",
    "num_genes = m_observed.shape[0]\n",
    "τ, common_indices = discretise(t)\n",
    "N_p = τ.shape[0]\n",
    "N_m = m_observed.shape[1]\n",
    "\n",
    "data = (m_observed, f_observed)\n",
    "time = (t, τ, tf.constant(common_indices))\n",
    "\n",
    "data = DataHolder(data, None, time)\n",
    "N_p = τ.shape[0]\n",
    "\n",
    "print(m_observed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt = Options(preprocessing_variance=False, \n",
    "              tf_mrna_present=True, \n",
    "              delays=False, \n",
    "              latent_function_metropolis=True,\n",
    "              kernel='rbf')\n",
    "T = 1000\n",
    "store_every = 1\n",
    "burn_in = 0\n",
    "report_every = 20\n",
    "num_chains = 4\n",
    "tune_every = 50\n",
    "\n",
    "\n",
    "model = TranscriptionMixedSampler(data, opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples, is_accepted = model.sample(T=300, burn_in=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = list()\n",
    "for i, param in enumerate(model.state_indices):\n",
    "    print(i)\n",
    "    pcs.append(tf.reduce_mean(tf.cast(is_accepted[i], dtype=tf.float32)).numpy())\n",
    "\n",
    "display(pd.DataFrame([[f'{100*pc:.02f}%' for pc in pcs]], columns=list(model.state_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "σ2_f = None\n",
    "kbar = model.samples[model.state_indices['kinetics']][0]\n",
    "k_fbar = model.samples[model.state_indices['kinetics']][1]\n",
    "fbar = model.samples[model.state_indices['fbar']]\n",
    "σ2_m = model.samples[model.state_indices['σ2_m']]\n",
    "# σ2_f = model.samples[model.state_indices['σ2_f']]\n",
    "kernel_params = model.samples[model.state_indices['kernel_params']]\n",
    "w = model.samples[model.state_indices['weights']][0]\n",
    "w_0 = model.samples[model.state_indices['weights']][1]\n",
    "\n",
    "# w = [1*tf.ones((num_genes, 1), dtype='float64')] # TODO\n",
    "# w_0 = [tf.zeros(num_genes, dtype='float64')] # TODO\n",
    "print(kbar[-1])\n",
    "\n",
    "m_preds = list()\n",
    "for i in range(1, 20):\n",
    "    m_preds.append(model.likelihood.predict_m(kbar[-i], k_fbar[-i], w[-1], fbar[-i], w_0[-1])) #todo w[-1]\n",
    "m_preds = np.array(m_preds)\n",
    "\n",
    "f_samples = np.log(1+np.exp(fbar))\n",
    "k_f_samples = logit(k_fbar).numpy()\n",
    "k_samples = logit(kbar).numpy()\n",
    "rbf_params_samples = [logit(kernel_params[0]), logit(kernel_params[1])] \n",
    "weights_samples = [logit(w), logit(w_0)]\n",
    "\n",
    "plotters.generate_report(data, k_samples, k_f_samples, f_samples, \n",
    "                         σ2_m, σ2_f, rbf_params_samples, m_preds, weights_samples,\n",
    "                         plot_barenco=True, gene_names=m_df.index, num_hpd=20, replicate=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_barenco = True\n",
    "plt.plot(fbar[:, 0, 0])\n",
    "fig = plt.figure(figsize=(13, 7))\n",
    "f_samples = np.log(1+np.exp(fbar[-100:, 0,:]))\n",
    "print(f_samples.shape)\n",
    "if 'σ2_f' in model.params._fields:\n",
    "    σ2_f = model.params.σ2_f.value\n",
    "    plt.errorbar(τ[common_indices], f_observed[0], 2*np.sqrt(σ2_f[0]), \n",
    "                 fmt='none', capsize=5, color='blue')\n",
    "else:\n",
    "    σ2_f = σ2_f_pre\n",
    "    \n",
    "bounds = arviz.hpd(f_samples, credible_interval=0.95)\n",
    "for i in range(1,20):\n",
    "    f_i = f_samples[-i]\n",
    "#     plt.plot(f_i)\n",
    "#     f_i[0] = 0\n",
    "    kwargs = {}\n",
    "    if i == 1:\n",
    "        kwargs = {'label':'Samples'}\n",
    "    plt.plot(τ, f_i, c='cadetblue', alpha=0.5, **kwargs)\n",
    "\n",
    "# if plot_barenco:\n",
    "#     barenco_f, _ = scaled_barenco_data(np.mean(f_samples[-10:], axis=0))\n",
    "#     plt.scatter(τ[common_indices], barenco_f, marker='x', s=60, linewidth=3, label='Barenco et al.')\n",
    "\n",
    "plt.scatter(τ[common_indices], f_observed[0], marker='x', s=70, linewidth=3, label='Observed')\n",
    "\n",
    "plt.fill_between(τ, bounds[:, 0], bounds[:, 1], color='grey', alpha=0.3, label='95% credibility interval')\n",
    "plt.xticks(t)\n",
    "fig.axes[0].set_xticklabels(t)\n",
    "plt.ylim((-1,5))\n",
    "plt.xlabel('Time (h)')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "num_genes = kbar.shape[1]\n",
    "k_latest = np.mean(logit(kbar[-10:]), axis=0)\n",
    "print(k_latest)\n",
    "B = k_latest[:,1]\n",
    "D = k_latest[:,2]\n",
    "S = k_latest[:,3]\n",
    "\n",
    "plt.bar(np.arange(num_genes)-0.2, B, width=0.2, tick_label=m_df.index, label='Basal rate')\n",
    "plt.bar(np.arange(num_genes), D, width=0.2, tick_label=m_df.index, label='Sensitivity')\n",
    "plt.bar(np.arange(num_genes)+0.2, S, width=0.2, tick_label=m_df.index, label='Decay rate')\n",
    "plt.yscale('log')\n",
    "plt.title('Mechanistic Parameters')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "plt.title('Noise variances')\n",
    "for i, j in enumerate(range(num_genes)):\n",
    "    ax = plt.subplot(num_genes, num_genes-2, i+1)\n",
    "    plt.title(m_df.index[j])\n",
    "    plt.plot(σ2_m[:,j])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = job[0].acceptance_rates.keys()\n",
    "\n",
    "variables = {key : np.empty((0, T, *job[0].samples[key].get().shape[1:])) for key in keys}\n",
    "\n",
    "for res in job:\n",
    "    for key in keys:\n",
    "        variables[key] = np.append(variables[key], np.expand_dims(res.samples[key].get(), 0), axis=0)\n",
    "\n",
    "plt.plot(variables['L'][:,-100:].T)\n",
    "\n",
    "mixes = {key: arviz.convert_to_inference_data(variables[key]) for key in keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rhat\n",
    "Rhat is the ratio of posterior variance and within-chain variance. If the ratio exceeds 1.1 then we consider the chains have not mixed well. As the between-chain variance tends to the within-chain then R tends to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rhat = arviz.rhat(mixes['fbar'])\n",
    "\n",
    "Rhats = np.array([np.mean(arviz.rhat(mixes[key]).x.values) for key in keys])\n",
    "\n",
    "rhat_df = pd.DataFrame([[*Rhats], [*(Rhats < 1.1)]], columns=keys)\n",
    "\n",
    "display(rhat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank plots\n",
    "\n",
    "Rank plots are histograms of the ranked posterior draws (ranked over all\n",
    "    chains) plotted separately for each chain.\n",
    "    If all of the chains are targeting the same posterior, we expect the ranks in each chain to be\n",
    "    uniform, whereas if one chain has a different location or scale parameter, this will be\n",
    "    reflected in the deviation from uniformity. If rank plots of all chains look similar, this\n",
    "    indicates good mixing of the chains.\n",
    "\n",
    "Rank-normalization, folding, and localization: An improved R-hat\n",
    "    for assessing convergence of MCMC. arXiv preprint https://arxiv.org/abs/1903.08008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_rank(L_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effective sample sizes\n",
    "\n",
    "Plot quantile, local or evolution of effective sample sizes (ESS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_ess(L_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monte-Carlo Standard Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_mcse(L_mix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parallel Plot\n",
    "Plot parallel coordinates plot showing posterior points with and without divergences.\n",
    "\n",
    "Described by https://arxiv.org/abs/1709.01449, suggested by Ari Hartikainen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arviz.plot_parallel(azl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step size is standard dev, too small means it takes long time to reach high density areas. too long means we reject many of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TranscriptionCustom(data, opt)\n",
    "fbar = tf.constant([[0.54880, 0.56062, 0.54973, 0.53923, 0.53923, 0.53892, 0.54077, 0.54334, 0.54586, 0.54953,\n",
    "  0.55446, 0.55897, 0.56173, 0.56379, 0.56612, 0.56790, 0.56781, 0.56570, 0.56276, 0.5914,\n",
    "  0.55507, 0.55068, 0.533, 0.54217, 0.53848, 0.53549, 0.53362, 0.53301, 0.53338, 0.53438,\n",
    "  0.53593, 0.53800, 0.54037, 0.54267, 0.54481, 0.54645, 0.54760, 0.54818, 0.54817, 0.54774,\n",
    "  0.54694, 0.54583, 0.5455, 0.54336, 0.54219, 0.54136, 0.54083, 0.54063, 0.54097, 0.54148,\n",
    "  0.54237, 0.54342, 0.54465, 0.510, 0.54804, 0.557, 0.5285, 0.5545, 0.55770, 0.5932,\n",
    "  0.56021, 0.56030, 0.55959, 0.534, 0.5654, 0.5417, 0.5162]], dtype='float64')\n",
    "print(fbar.shape)\n",
    "#  1.4018160215788704 4.4271686734681195\n",
    "print(model.params.V.prior.log_prob(1.3818811998078957))\n",
    "print(model.params.L.prior.log_prob(3.9525443383480283))\n",
    "\n",
    "# fbar = model.params.fbar.value\n",
    "print(model.params.fbar.prior(fbar, f64(0.6), f64(0.99)))\n",
    "#  3.9525443383480283"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit374b75da0e1b40de8b7922d3f142c01d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
