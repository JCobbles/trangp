{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gpflow as gpf\n",
    "import tensorflow as tf\n",
    "\n",
    "from gpflow.utilities import print_summary\n",
    "from gpflow.ci_utils import ci_niter\n",
    "\n",
    "from reggae.data_loaders import load_barenco_puma, DataHolder\n",
    "from reggae.gp import LinearResponseKernel, LinearResponseMeanFunction\n",
    "from reggae.gp.sim_kernels import LinearCoregionalization\n",
    "\n",
    "gpf.config.set_default_float(np.float64)\n",
    "gpf.config.set_default_summary_fmt(\"notebook\")\n",
    "np.random.seed(0)\n",
    "%matplotlib inline\n",
    "\n",
    "f64 = np.float64\n",
    "MAXITER = ci_niter(2000)\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_observed, f_observed, σ2_m_pre, σ2_f_pre, t = load_barenco_puma()\n",
    "m_df, m_observed = m_observed \n",
    "f_df, f_observed = f_observed\n",
    "# Shape of m_observed = (replicates, genes, times)\n",
    "m_observed = m_observed\n",
    "f_observed = f_observed\n",
    "data = (m_observed, f_observed)\n",
    "\n",
    "σ2_m_pre = f64(σ2_m_pre)\n",
    "σ2_f_pre = f64(σ2_f_pre)\n",
    "noise_data = (σ2_m_pre, σ2_f_pre)\n",
    "\n",
    "\n",
    "num_genes = m_observed.shape[1]\n",
    "N_m = m_observed.shape[2]\n",
    "granularity = 100\n",
    "τ = np.linspace(0, 12, granularity)\n",
    "time = (t, τ, None)\n",
    "data = DataHolder(data, noise_data, time)\n",
    "\n",
    "Y_var = data.σ2_m_pre[0].reshape(-1)\n",
    "\n",
    "m_obs = m_observed #(Nr, J, Nm)\n",
    "m_obs[0, 3] = np.array([2, 2.5, 1.5, 1, 0.5, 0.6, 0.3])\n",
    "N = 35#m_obs.shape[2]  # number of points\n",
    "D = 1  # number of input dimensions\n",
    "M = N  # number of inducing points\n",
    "L = 2  # number of latent GPs\n",
    "P = m_obs.shape[1]  # number of observations = output dimensions\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m_obs.shape)\n",
    "plt.plot(m_obs[0, 0])\n",
    "plt.plot([2, 2.5, 1.5, 1, 0.5, 0.6, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N=100):\n",
    "    X = np.random.rand(N)[:, None] * 10 - 5  # Inputs = N x D\n",
    "    G = np.hstack((0.5 * np.sin(3 * X) + X, 3.0 * np.cos(X) - X))  # G = N x L\n",
    "    W = np.array([[0.5, -0.3, 1.5], [-0.4, 0.43, 0.0]])  # L x P\n",
    "    F = np.matmul(G, W)  # N x P\n",
    "    Y = F + np.random.randn(*F.shape) * [0.2, 0.2, 0.2]\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[[np.float64(t) for _ in range(num_genes)]].reshape(-1, 1)\n",
    "X, Y = XY = X, np.tile(m_obs[0].reshape(-1, 1), (1, 5))#m_obs[0].T\n",
    "Zinit = X#t[:, None] #np.linspace(-5, 5, M)[:, None]\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(m, lower=0, upper=14.0):\n",
    "    pX = np.linspace(lower, upper, 100)[:, None]\n",
    "    pY, pYv = m.predict_y(pX)\n",
    "    if pY.ndim == 3:\n",
    "        pY = pY[:, 0, :]\n",
    "    print(X.shape, Y.shape)\n",
    "    for i in range(Y.shape[1]):        \n",
    "        plt.plot(X[:,0], Y[:,i], \"x\", label=i)\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    plt.plot(pX, pY)\n",
    "    for i in range(pY.shape[1]):\n",
    "        top = pY[:, i] + 2.0 * pYv[:, i] ** 0.5\n",
    "        bot = pY[:, i] - 2.0 * pYv[:, i] ** 0.5\n",
    "        plt.fill_between(pX[:, 0], top, bot, alpha=0.3)\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"f\")\n",
    "    plt.title(f\"ELBO: {m.elbo(XY):.3}\")\n",
    "    plt.plot(Z, Z * 0.0, \"o\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def optimize_model_with_scipy(model):\n",
    "    optimizer = gpf.optimizers.Scipy()\n",
    "    log = optimizer.minimize(\n",
    "        model.training_loss_closure(XY),\n",
    "        variables=model.trainable_variables,\n",
    "        method=\"l-bfgs-b\",\n",
    "        options={\"disp\": True, \"maxiter\": MAXITER},\n",
    "    )\n",
    "    return log\n",
    "\n",
    "# optimize_model_with_scipy(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of kernels for each output\n",
    "kern_list = [gpf.kernels.SquaredExponential() + gpf.kernels.Linear() for _ in range(L)]\n",
    "kern_list = [LinearResponseKernel(data, Y_var) + gpf.kernels.Linear() for _ in range(L)]\n",
    "\n",
    "# Create multi-output kernel from kernel list\n",
    "kernel = gpf.kernels.LinearCoregionalization(\n",
    "    kern_list, W=np.random.randn(P, L)\n",
    ")  # Notice that we initialise the mixing matrix W\n",
    "# initialisation of inducing input locations (M random points from the training inputs)\n",
    "Z = Zinit.copy()\n",
    "# create multi-output inducing variables from Z\n",
    "iv = gpf.inducing_variables.SharedIndependentInducingVariables(\n",
    "    gpf.inducing_variables.InducingPoints(Z)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize mean of variational posterior to be of shape MxL\n",
    "q_mu = np.zeros((M, L))\n",
    "# initialize \\sqrt(Σ) of variational posterior to be of shape LxMxM\n",
    "q_sqrt = np.repeat(np.eye(M)[None, ...], L, axis=0) * 1.0\n",
    "\n",
    "# create SVGP model as usual and optimize\n",
    "m = gpf.models.SVGP(\n",
    "    kernel, gpf.likelihoods.Gaussian(), inducing_variable=iv, q_mu=q_mu, q_sqrt=q_sqrt\n",
    ")\n",
    "# m = gpf.models.VGP(XY, kernel, gpf.likelihoods.Gaussian())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimize_model_with_scipy(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create multi-output kernel\n",
    "kernel = gpf.kernels.SharedIndependent(\n",
    "    LinearResponseKernel(data, Y_var), output_dim=P\n",
    ")\n",
    "# initialization of inducing input locations (M random points from the training inputs)\n",
    "Z = Zinit.copy()\n",
    "# create multi-output inducing variables from Z\n",
    "iv = gpf.inducing_variables.SharedIndependentInducingVariables(\n",
    "    gpf.inducing_variables.InducingPoints(Z)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SVGP model as usual and optimize\n",
    "# m = gpf.models.SVGP(kernel, gpf.likelihoods.Gaussian(), inducing_variable=iv, num_latent_gps=P)\n",
    "m = gpf.models.VGP(XY, kernel, gpf.likelihoods.Gaussian(), num_latent_gps=P)\n",
    "print_summary(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LinearResponseKernel(data, Y_var).K(X).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = tf.random.normal((5, 2), dtype='float64')\n",
    "K = tf.stack([k.K_diag(X) for k in kernel.kernels], axis=1)\n",
    "# k = tf.random.normal((2, 12, 12))\n",
    "print(w[:,:,None,None].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reggae.utilities import broadcast_tile\n",
    "print(K.shape)\n",
    "print(K[:,:,None, None].shape)\n",
    "w = broadcast_tile(w, 7, 1)\n",
    "wt = tf.transpose(w)\n",
    "print(wt.shape)\n",
    "print(tf.reduce_sum(K[:,:,None, None] * wt[None, :,:,None]* wt[None, :, None, :], axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = m.kernel(X) + tf.eye(35, dtype='float64') * 1e-6\n",
    "L = tf.linalg.cholesky(K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_tiled = tf.tile(tf.expand_dims(L, 0), tf.stack([2, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_summary(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_summary(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.kernel.W.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m.kernel.W.numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
